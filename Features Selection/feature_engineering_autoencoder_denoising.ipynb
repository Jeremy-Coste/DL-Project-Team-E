{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T12:44:09.131674Z",
     "start_time": "2018-10-02T12:44:09.129175Z"
    }
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.460211Z",
     "start_time": "2018-10-03T22:37:49.443514Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meihuaren/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_csv('all_features_new_64.csv')\n",
    "\n",
    "# After PCA or AutoEncoder，features do not contain 'ask_price_1' and 'bid_price_1', \n",
    "# thus, we calculate and store the label first though there is no use in the feature selection part.\n",
    "data = all_features.fillna(method='ffill')\n",
    "data['mid_price'] = (data['ask_price_1'] + data['bid_price_1']) / 2\n",
    "data['d_price'] = data['mid_price'].diff().shift(-1)\n",
    "data['label'] = 1*(data['d_price']>0) - 1*(data['d_price']<0)\n",
    "data = data.dropna() # drop the first 6 rows (with some nan features) and the last row (with nan 'd_price')\n",
    "data = data.drop(['mid_price', 'd_price'], axis=1)\n",
    "\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581023, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_vol_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_vol_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_vol_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_vol_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_vol_3</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_bid_vol_4</th>\n",
       "      <th>rank_ask_vol_4</th>\n",
       "      <th>rank_bid_vol_5</th>\n",
       "      <th>rank_ask_vol_5</th>\n",
       "      <th>corr_vol_1</th>\n",
       "      <th>corr_vol_2</th>\n",
       "      <th>corr_vol_3</th>\n",
       "      <th>corr_vol_4</th>\n",
       "      <th>corr_vol_5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.353553</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.395285</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>300</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.408248</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275200</td>\n",
       "      <td>100</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>300</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.228210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_price_1  ask_vol_1  bid_price_1  bid_vol_1  ask_price_2  ask_vol_2  \\\n",
       "0       275200        166       275100        300       275300       1000   \n",
       "1       275200        166       275100        300       275300       1000   \n",
       "2       275200        166       275100        300       275300       1000   \n",
       "3       275200        166       275100        300       275300       1000   \n",
       "4       275200        100       275100        300       275300       1000   \n",
       "\n",
       "   bid_price_2  bid_vol_2  ask_price_3  ask_vol_3  ...    rank_bid_vol_4  \\\n",
       "0       275000        100       275400        373  ...               1.0   \n",
       "1       275000        100       275400        373  ...               1.0   \n",
       "2       275000        100       275400        373  ...               1.0   \n",
       "3       275000        300       275400        373  ...               1.0   \n",
       "4       275000        300       275400        373  ...               1.0   \n",
       "\n",
       "   rank_ask_vol_4  rank_bid_vol_5  rank_ask_vol_5  corr_vol_1  corr_vol_2  \\\n",
       "0             1.0        0.714286             1.0   -0.353553        -1.0   \n",
       "1             1.0        0.750000             1.0   -0.377964        -1.0   \n",
       "2             1.0        1.000000             1.0   -0.395285        -1.0   \n",
       "3             1.0        1.000000             1.0   -0.408248        -1.0   \n",
       "4             1.0        1.000000             1.0   -0.228210         1.0   \n",
       "\n",
       "   corr_vol_3  corr_vol_4  corr_vol_5  label  \n",
       "0        -1.0        -1.0         1.0      0  \n",
       "1        -1.0        -1.0         1.0      0  \n",
       "2        -1.0        -1.0         1.0      0  \n",
       "3        -1.0        -1.0         1.0      0  \n",
       "4        -1.0         1.0         1.0      1  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight = 0.8\n",
    "split = int(data.shape[0] * train_weight)\n",
    "df_train = data.iloc[:split,:-1]\n",
    "df_test = data.iloc[split:,:-1]\n",
    "\n",
    "nrow = 3000\n",
    "df_valid = df_test[0:nrow]\n",
    "df_test = df_test[nrow:]\n",
    "\n",
    "x_train = df_train.values\n",
    "x_valid = df_valid.values\n",
    "x_test = df_test.values\n",
    "x_all = data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization (to make sure the autoencoder is converging)\n",
    "x_max = np.max(x_train,axis=0)\n",
    "x_min = np.min(x_train,axis=0)\n",
    "x_train = (x_train - x_min) / (x_max - x_min)\n",
    "x_valid = (x_valid - x_min) / (x_max - x_min)\n",
    "x_test = (x_test - x_min) / (x_max - x_min)\n",
    "x_all = (x_all - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464818, 64) (3000, 64) (113205, 64) (581023, 64)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_valid.shape, x_test.shape, x_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.476437Z",
     "start_time": "2018-10-03T22:38:03.462522Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 64\n",
    "#re-constructed size\n",
    "output_size = 64\n",
    "\n",
    "# 3 hidden layers for encoder\n",
    "n_encoder_h_1 = 32\n",
    "n_encoder_h_2 = 16\n",
    "n_encoder_h_3 = 8\n",
    "\n",
    "# 3 hidden layers for decoder\n",
    "n_decoder_h_1 = 8\n",
    "n_decoder_h_2 = 16\n",
    "n_decoder_h_3 = 32\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 200 #200\n",
    "batch_size = 200\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.527109Z",
     "start_time": "2018-10-03T22:38:03.479053Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer_batch_normalization(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - n_out: integer, depth of input maps - number of sample in the batch \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - batch-normalized maps   \n",
    "    \"\"\"\n",
    "\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    \n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "    #calculate mean and variance of x\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "\n",
    "    #tf.train.ExponentialMovingAverage:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    #Maintains moving averages of variables by employing an exponential decay.\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "       \n",
    "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
    "    #Return true_fn() if the predicate pred is true else false_fn()\n",
    "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    #normed = tf.nn.batch_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    return tf.reshape(normed, [-1, n_out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.574224Z",
     "start_time": "2018-10-03T22:38:03.529227Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer(x, weight_shape, bias_shape, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize weights\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    \n",
    "    #apply the non-linear function after the batch normalization\n",
    "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))\n",
    "    # Using sigmoid to avoid sharp transitions in neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:39:04.039484Z",
     "start_time": "2018-10-02T13:39:04.036698Z"
    }
   },
   "source": [
    "# Definition of the Encoder Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.598508Z",
     "start_time": "2018-10-03T22:38:03.576953Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the encoder\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reduced dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        with tf.variable_scope(\"h_1\"):\n",
    "            h_1 = layer(x, [input_size, n_encoder_h_1], [n_encoder_h_1], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"h_2\"):\n",
    "            h_2 = layer(h_1, [n_encoder_h_1, n_encoder_h_2], [n_encoder_h_2], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"h_3\"):\n",
    "            h_3 = layer(h_2, [n_encoder_h_2, n_encoder_h_3], [n_encoder_h_3], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"code\"):\n",
    "            output = layer(h_3, [n_encoder_h_3, n_code], [n_code], phase_train)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:39:56.962874Z",
     "start_time": "2018-10-02T13:39:56.960040Z"
    }
   },
   "source": [
    "# Definition of the Decoder Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.634567Z",
     "start_time": "2018-10-03T22:38:03.600519Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the decoder - reduced dimension vector\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reconstructed dimension of the initial vector\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "        with tf.variable_scope(\"h_1\"):\n",
    "            h_1 = layer(x, [n_code, n_decoder_h_1], [n_decoder_h_1], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"h_2\"):\n",
    "            h_2 = layer(h_1, [n_decoder_h_1, n_decoder_h_2], [n_decoder_h_2], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"h_3\"):\n",
    "            h_3 = layer(h_2, [n_decoder_h_2, n_decoder_h_3], [n_decoder_h_3], phase_train)\n",
    "\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(h_3, [n_decoder_h_3, output_size], [output_size], phase_train)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:39:56.962874Z",
     "start_time": "2018-10-02T13:39:56.960040Z"
    }
   },
   "source": [
    "# Definition of the Corrupt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four ways to corrupt input:\n",
    "\n",
    "# Corrupt: The original input elements are forced to zero, kept the same or multiplied by 2\n",
    "def corrupt_x(x):\n",
    "    \n",
    "    #Multiplied the input with a random int matrix with the same shape generated from [0,1,2] to add more randomness to the input\n",
    "    #Add this function in the structure of tensorflow to avoid overfitting\n",
    "    \n",
    "    c = tf.random_uniform(shape=tf.shape(x),  minval=0, maxval=2, dtype=tf.int32)\n",
    "    #c = 1.0\n",
    "    #to do multiplication, first need to convert the data to the same type which is tf.float32\n",
    "    x_tilde = x * tf.cast(c, tf.float32)\n",
    "    \n",
    "    return x_tilde\n",
    "\n",
    "\n",
    "# Salt and pepper noise: randomly change some of the original data point to minimum or maximum\n",
    "def salt_and_pepper_noise(input, v):\n",
    " \n",
    "    #Apply salt and pepper noise to data in input, in other words a fraction v of elements of input (chosen at random) is set to its maximum or minimum value according to a fair coin flip.\n",
    "    #If minimum or maximum are not given, the min (max) value in input is taken.\n",
    "    #param input: array_like, Input data\n",
    "    #param v: int, fraction of elements to distort\n",
    "    #return: transformed data\n",
    "    \n",
    "    input_noise = input.copy()\n",
    "    #shape(input) is (sample_size,number_of_features)\n",
    "    n_features = input.shape[1]\n",
    "\n",
    "    mn = input.min()\n",
    "    mx = input.max()\n",
    "\n",
    "    for i, sample in enumerate(input):\n",
    "        #randomly generate a array-like mask with a length as v\n",
    "        mask = np.random.randint(0, n_features, v)\n",
    "\n",
    "        for m in mask:\n",
    "            #set the mask point to minimum or maximum according to a Bernoulli(0.5)\n",
    "            if np.random.random() < 0.5:\n",
    "                input_noise[i][m] = mn\n",
    "            else:\n",
    "                input_noise[i][m] = mx\n",
    "\n",
    "    return input_noise\n",
    "\n",
    "\n",
    "# Masking Noise: Randomly select a fraction of input and force them to zero\n",
    "def masking_noise(input, v):\n",
    "    \n",
    "    #Apply masking noise to data in input, in other words a fraction v of elements of input (chosen at random) is forced to zero.\n",
    "    #param input: array_like, Input data\n",
    "    #param v: int, fraction of elements to distort\n",
    "    #return: transformed data\n",
    "    \n",
    "    input_noise = input.copy()\n",
    "\n",
    "    n_samples = input.shape[0]\n",
    "    n_features = input.shape[1]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        mask = np.random.randint(0, n_features, v)\n",
    "        #set all masked data points to be zero\n",
    "        for m in mask:\n",
    "            input_noise[i][m] = 0.\n",
    "\n",
    "    return input_noise\n",
    "\n",
    "\n",
    "def add_gaussian_noise(inputX, mean, stddev):\n",
    "\n",
    "    n_rows = inputX.shape[0]\n",
    "    n_cols = inputX.shape[1]\n",
    "    \n",
    "    noise = np.random.normal(mean, stddev, (n_rows, n_cols))\n",
    "    \n",
    "    # creating the noisy test data by adding X_test with noise\n",
    "    \n",
    "    noisyX = inputX + noise\n",
    "    \n",
    "    return noisyX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:39:56.962874Z",
     "start_time": "2018-10-02T13:39:56.960040Z"
    }
   },
   "source": [
    "# Definition of the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.646821Z",
     "start_time": "2018-10-03T22:38:03.637606Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss is L2 measure\n",
    "def loss(output, x):\n",
    "    \"\"\"\n",
    "    Compute the loss of the auto-encoder\n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the decoder\n",
    "        - x: true value of the sample batch - this is the input of the encoder\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"training\"):\n",
    "        \n",
    "        l2_measure = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
    "        train_loss = tf.reduce_mean(l2_measure)\n",
    "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
    "        return train_loss, train_summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.661733Z",
     "start_time": "2018-10-03T22:38:03.650651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using Adam as optimizer for training \t\n",
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:38:03.705246Z",
     "start_time": "2018-10-03T22:38:03.664581Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(output, x):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        - output: prediction vector of the network for the validation set\n",
    "        - x: true value for the validation set\n",
    "    output:\n",
    "        - val_loss: loss of the autoencoder\n",
    "        - val_summary_op: summary of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        \n",
    "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
    "        \n",
    "        val_loss = tf.reduce_mean(l2_norm)\n",
    "        \n",
    "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
    "        \n",
    "        return val_loss, val_summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:51:07.293398Z",
     "start_time": "2018-10-02T13:51:07.282274Z"
    }
   },
   "source": [
    "# Main Function - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T22:48:13.428734Z",
     "start_time": "2018-10-03T22:38:03.731572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.967063439\n",
      "Validation Loss: 1.682285\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0002 cost = 1.672280170\n",
      "Validation Loss: 1.6008494\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0003 cost = 1.622828684\n",
      "Validation Loss: 1.5671675\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0004 cost = 1.594543621\n",
      "Validation Loss: 1.531435\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0005 cost = 1.586730693\n",
      "Validation Loss: 1.6603447\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0006 cost = 1.555258383\n",
      "Validation Loss: 1.5705175\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0007 cost = 1.556947282\n",
      "Validation Loss: 1.4977608\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0008 cost = 1.544114790\n",
      "Validation Loss: 1.5637513\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0009 cost = 1.525053997\n",
      "Validation Loss: 1.5641292\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0010 cost = 1.522482813\n",
      "Validation Loss: 1.8264326\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0011 cost = 1.516896463\n",
      "Validation Loss: 1.4997104\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0012 cost = 1.512613965\n",
      "Validation Loss: 1.6613352\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0013 cost = 1.504267660\n",
      "Validation Loss: 1.5866592\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0014 cost = 1.514986279\n",
      "Validation Loss: 1.6130444\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0015 cost = 1.505765214\n",
      "Validation Loss: 1.5962467\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0016 cost = 1.497504962\n",
      "Validation Loss: 1.7370083\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0017 cost = 1.503739684\n",
      "Validation Loss: 1.5073961\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0018 cost = 1.480492282\n",
      "Validation Loss: 1.8702106\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0019 cost = 1.470027275\n",
      "Validation Loss: 1.5360005\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0020 cost = 1.501690320\n",
      "Validation Loss: 1.8274643\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0021 cost = 1.484395033\n",
      "Validation Loss: 1.5849212\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0022 cost = 1.478900638\n",
      "Validation Loss: 1.6183565\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0023 cost = 1.480194002\n",
      "Validation Loss: 1.6238965\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0024 cost = 1.501898423\n",
      "Validation Loss: 1.5367061\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0025 cost = 1.483158922\n",
      "Validation Loss: 3.0567076\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0026 cost = 1.503304844\n",
      "Validation Loss: 1.6065964\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0027 cost = 1.477174033\n",
      "Validation Loss: 1.5211061\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0028 cost = 1.486442182\n",
      "Validation Loss: 3.4332044\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0029 cost = 1.497457238\n",
      "Validation Loss: 1.6298535\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0030 cost = 1.495008642\n",
      "Validation Loss: 1.8814558\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0031 cost = 1.495771728\n",
      "Validation Loss: 2.1519961\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0032 cost = 1.484228309\n",
      "Validation Loss: 1.5203024\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0033 cost = 1.471473793\n",
      "Validation Loss: 1.8190112\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0034 cost = 1.448610966\n",
      "Validation Loss: 1.5808899\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0035 cost = 1.458469261\n",
      "Validation Loss: 1.5698941\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0036 cost = 1.447038511\n",
      "Validation Loss: 1.5981627\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0037 cost = 1.461883816\n",
      "Validation Loss: 1.5656201\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0038 cost = 1.469760956\n",
      "Validation Loss: 1.5975254\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0039 cost = 1.458332326\n",
      "Validation Loss: 1.5461686\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0040 cost = 1.446024331\n",
      "Validation Loss: 1.6042681\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0041 cost = 1.451670711\n",
      "Validation Loss: 1.6867083\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0042 cost = 1.444709988\n",
      "Validation Loss: 1.8778563\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0043 cost = 1.437842024\n",
      "Validation Loss: 1.7132368\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0044 cost = 1.461273171\n",
      "Validation Loss: 1.5168774\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0045 cost = 1.453403326\n",
      "Validation Loss: 1.5732646\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0046 cost = 1.447138900\n",
      "Validation Loss: 1.7622118\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0047 cost = 1.467630427\n",
      "Validation Loss: 1.6518476\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0048 cost = 1.450868954\n",
      "Validation Loss: 1.5903665\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0049 cost = 1.452931207\n",
      "Validation Loss: 1.578049\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0050 cost = 1.435325429\n",
      "Validation Loss: 1.893136\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0051 cost = 1.452602861\n",
      "Validation Loss: 1.5897334\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0052 cost = 1.444129311\n",
      "Validation Loss: 1.6702689\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0053 cost = 1.442718182\n",
      "Validation Loss: 1.7411084\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0054 cost = 1.457056863\n",
      "Validation Loss: 1.6477852\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0055 cost = 1.445325971\n",
      "Validation Loss: 1.6112409\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0056 cost = 1.439031566\n",
      "Validation Loss: 1.5894544\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0057 cost = 1.439189149\n",
      "Validation Loss: 1.7767545\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0058 cost = 1.448546799\n",
      "Validation Loss: 1.7238942\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0059 cost = 1.441215940\n",
      "Validation Loss: 1.745322\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0060 cost = 1.431488361\n",
      "Validation Loss: 1.7232116\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0061 cost = 1.427953564\n",
      "Validation Loss: 1.5749815\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0062 cost = 1.438447106\n",
      "Validation Loss: 1.7268257\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0063 cost = 1.431918881\n",
      "Validation Loss: 1.813154\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0064 cost = 1.430509442\n",
      "Validation Loss: 1.7832112\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0065 cost = 1.424314557\n",
      "Validation Loss: 1.8159585\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0066 cost = 1.426216505\n",
      "Validation Loss: 2.1271749\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0067 cost = 1.423400461\n",
      "Validation Loss: 1.6726147\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0068 cost = 1.410159689\n",
      "Validation Loss: 3.4751575\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0069 cost = 1.432967465\n",
      "Validation Loss: 1.6969925\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0070 cost = 1.418783263\n",
      "Validation Loss: 2.0238352\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0071 cost = 1.438964052\n",
      "Validation Loss: 1.648733\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0072 cost = 1.431485233\n",
      "Validation Loss: 1.7409585\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0073 cost = 1.423093045\n",
      "Validation Loss: 1.5631247\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0074 cost = 1.468782530\n",
      "Validation Loss: 1.8723897\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0075 cost = 1.457758317\n",
      "Validation Loss: 1.8086392\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0076 cost = 1.438758797\n",
      "Validation Loss: 2.3714447\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0077 cost = 1.444294961\n",
      "Validation Loss: 1.8064828\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0078 cost = 1.436008728\n",
      "Validation Loss: 1.8017377\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0079 cost = 1.422664580\n",
      "Validation Loss: 1.9154446\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0080 cost = 1.418411598\n",
      "Validation Loss: 1.7039242\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0081 cost = 1.413569412\n",
      "Validation Loss: 3.1094418\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0082 cost = 1.429349129\n",
      "Validation Loss: 2.1903434\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0083 cost = 1.414301918\n",
      "Validation Loss: 1.8358418\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0084 cost = 1.417630691\n",
      "Validation Loss: 1.6147723\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0085 cost = 1.401662465\n",
      "Validation Loss: 1.7986703\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0086 cost = 1.410071256\n",
      "Validation Loss: 1.652682\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0087 cost = 1.407540076\n",
      "Validation Loss: 1.6184691\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0088 cost = 1.406410708\n",
      "Validation Loss: 1.6391084\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0089 cost = 1.409647493\n",
      "Validation Loss: 1.9791907\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0090 cost = 1.401960704\n",
      "Validation Loss: 1.6866739\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0091 cost = 1.439855458\n",
      "Validation Loss: 1.7282765\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0092 cost = 1.419348787\n",
      "Validation Loss: 1.7934633\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0093 cost = 1.424991447\n",
      "Validation Loss: 2.507838\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0094 cost = 1.427397090\n",
      "Validation Loss: 1.8240811\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0095 cost = 1.419786077\n",
      "Validation Loss: 1.6659721\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0096 cost = 1.428647668\n",
      "Validation Loss: 1.6042762\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0097 cost = 1.422378498\n",
      "Validation Loss: 1.5833968\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0098 cost = 1.426189477\n",
      "Validation Loss: 3.0312421\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0099 cost = 1.432907788\n",
      "Validation Loss: 1.5659838\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0100 cost = 1.423461129\n",
      "Validation Loss: 1.5778037\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0101 cost = 1.427645559\n",
      "Validation Loss: 1.9014196\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0102 cost = 1.427029334\n",
      "Validation Loss: 3.117494\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0103 cost = 1.434635392\n",
      "Validation Loss: 1.6412897\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0104 cost = 1.439872477\n",
      "Validation Loss: 1.6573563\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0105 cost = 1.439215241\n",
      "Validation Loss: 1.6085634\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0106 cost = 1.504166196\n",
      "Validation Loss: 1.6584687\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0107 cost = 1.452862628\n",
      "Validation Loss: 1.6618047\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0108 cost = 1.436572552\n",
      "Validation Loss: 3.204782\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0109 cost = 1.442509126\n",
      "Validation Loss: 1.671061\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0110 cost = 1.536174217\n",
      "Validation Loss: 1.6527021\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0111 cost = 1.433568536\n",
      "Validation Loss: 1.6885257\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0112 cost = 1.494808004\n",
      "Validation Loss: 1.6985077\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0113 cost = 1.485384909\n",
      "Validation Loss: 1.6469953\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0114 cost = 1.454969520\n",
      "Validation Loss: 1.6260074\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0115 cost = 1.456399698\n",
      "Validation Loss: 1.7405306\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0116 cost = 1.540905483\n",
      "Validation Loss: 1.7131233\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0117 cost = 1.470418223\n",
      "Validation Loss: 1.5550367\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0118 cost = 1.497206441\n",
      "Validation Loss: 1.7058988\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0119 cost = 1.444358693\n",
      "Validation Loss: 1.6870949\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0120 cost = 1.443833744\n",
      "Validation Loss: 1.5615226\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0121 cost = 1.439873266\n",
      "Validation Loss: 1.5965264\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0122 cost = 1.439866331\n",
      "Validation Loss: 1.6119033\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0123 cost = 1.439295237\n",
      "Validation Loss: 1.6495125\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0124 cost = 1.433359885\n",
      "Validation Loss: 1.676698\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0125 cost = 1.485751128\n",
      "Validation Loss: 1.593625\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0126 cost = 1.436079156\n",
      "Validation Loss: 1.7799151\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0127 cost = 1.488240787\n",
      "Validation Loss: 1.656263\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0128 cost = 1.449216834\n",
      "Validation Loss: 1.6350373\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0129 cost = 1.438095570\n",
      "Validation Loss: 1.6360573\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0130 cost = 1.463395999\n",
      "Validation Loss: 1.5995091\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0131 cost = 1.461535559\n",
      "Validation Loss: 1.5565556\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0132 cost = 1.454894492\n",
      "Validation Loss: 1.5108678\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0133 cost = 1.433915381\n",
      "Validation Loss: 1.5917927\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0134 cost = 1.436469929\n",
      "Validation Loss: 1.567356\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0135 cost = 1.467468363\n",
      "Validation Loss: 1.7004914\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0136 cost = 1.433698607\n",
      "Validation Loss: 1.6033472\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0137 cost = 1.424991988\n",
      "Validation Loss: 1.6087415\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0138 cost = 1.429162377\n",
      "Validation Loss: 1.5690576\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0139 cost = 1.423375177\n",
      "Validation Loss: 1.6247087\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0140 cost = 1.421488493\n",
      "Validation Loss: 1.6746577\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0141 cost = 1.423247069\n",
      "Validation Loss: 1.568325\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0142 cost = 1.426768863\n",
      "Validation Loss: 1.5632569\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0143 cost = 1.420011314\n",
      "Validation Loss: 1.5556462\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0144 cost = 1.427776566\n",
      "Validation Loss: 1.6020598\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0145 cost = 1.421710238\n",
      "Validation Loss: 1.6017483\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0146 cost = 1.421437773\n",
      "Validation Loss: 1.5936133\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0147 cost = 1.422577101\n",
      "Validation Loss: 1.5875007\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0148 cost = 1.423014400\n",
      "Validation Loss: 1.5312093\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0149 cost = 1.415566789\n",
      "Validation Loss: 1.5573157\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0150 cost = 1.410885804\n",
      "Validation Loss: 1.5255578\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0151 cost = 1.415205093\n",
      "Validation Loss: 1.6341562\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0152 cost = 1.430726644\n",
      "Validation Loss: 1.5696238\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0153 cost = 1.412982931\n",
      "Validation Loss: 1.5081706\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0154 cost = 1.407841597\n",
      "Validation Loss: 1.5194696\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0155 cost = 1.412831640\n",
      "Validation Loss: 1.5542597\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0156 cost = 1.407102959\n",
      "Validation Loss: 1.5294195\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0157 cost = 1.408014945\n",
      "Validation Loss: 1.5241585\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0158 cost = 1.408674530\n",
      "Validation Loss: 1.539639\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0159 cost = 1.410801173\n",
      "Validation Loss: 1.7344807\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0160 cost = 1.417782453\n",
      "Validation Loss: 1.5284128\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0161 cost = 1.417886402\n",
      "Validation Loss: 1.5369427\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0162 cost = 1.419681372\n",
      "Validation Loss: 1.5020436\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0163 cost = 1.413939891\n",
      "Validation Loss: 1.5622077\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0164 cost = 1.414431558\n",
      "Validation Loss: 1.577557\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0165 cost = 1.413236152\n",
      "Validation Loss: 1.5841976\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0166 cost = 1.417055564\n",
      "Validation Loss: 1.5199986\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0167 cost = 1.411254738\n",
      "Validation Loss: 1.5062399\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0168 cost = 1.417420063\n",
      "Validation Loss: 1.578417\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0169 cost = 1.415424024\n",
      "Validation Loss: 1.5338562\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0170 cost = 1.414395663\n",
      "Validation Loss: 1.504219\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0171 cost = 1.410530835\n",
      "Validation Loss: 1.5057241\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0172 cost = 1.412537273\n",
      "Validation Loss: 1.5401592\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0173 cost = 1.413657891\n",
      "Validation Loss: 1.5813406\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0174 cost = 1.411803104\n",
      "Validation Loss: 1.5236123\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0175 cost = 1.413743121\n",
      "Validation Loss: 1.5310124\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0176 cost = 1.415824870\n",
      "Validation Loss: 1.5101264\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0177 cost = 1.413205036\n",
      "Validation Loss: 1.5552757\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0178 cost = 1.410715715\n",
      "Validation Loss: 1.5326673\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0179 cost = 1.414535944\n",
      "Validation Loss: 1.5371547\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0180 cost = 1.407962108\n",
      "Validation Loss: 1.5649053\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0181 cost = 1.405257868\n",
      "Validation Loss: 1.5299687\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0182 cost = 1.402210711\n",
      "Validation Loss: 1.5231605\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0183 cost = 1.405168963\n",
      "Validation Loss: 1.5310414\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0184 cost = 1.416976369\n",
      "Validation Loss: 1.5347084\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0185 cost = 1.411845179\n",
      "Validation Loss: 1.5048399\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0186 cost = 1.411986562\n",
      "Validation Loss: 1.5296494\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0187 cost = 1.406143929\n",
      "Validation Loss: 1.5091923\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0188 cost = 1.412690747\n",
      "Validation Loss: 1.541266\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0189 cost = 1.410120756\n",
      "Validation Loss: 1.5407093\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0190 cost = 1.412289078\n",
      "Validation Loss: 1.522409\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0191 cost = 1.408809962\n",
      "Validation Loss: 1.5344812\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0192 cost = 1.410938114\n",
      "Validation Loss: 1.5394162\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0193 cost = 1.414100611\n",
      "Validation Loss: 1.55701\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0194 cost = 1.417542542\n",
      "Validation Loss: 1.5122657\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0195 cost = 1.412362781\n",
      "Validation Loss: 1.4989651\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0196 cost = 1.416002482\n",
      "Validation Loss: 1.5278834\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0197 cost = 1.410930319\n",
      "Validation Loss: 1.5492185\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0198 cost = 1.408213752\n",
      "Validation Loss: 1.5115786\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0199 cost = 1.407737064\n",
      "Validation Loss: 1.501905\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Epoch: 0200 cost = 1.412660429\n",
      "Validation Loss: 1.5159528\n",
      "Model saved in file: /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Optimization Done\n",
      "Test Loss: 1.5814415\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
    "    #parser.add_argument('n_code', nargs=1, type=str)\n",
    "    #args = parser.parse_args(['--help'])\n",
    "    #n_code = args.n_code[0]\n",
    "    \n",
    "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
    "    n_code = '8'\n",
    "    \n",
    "    #feel free to change with your own\n",
    "    model_path = '/Users/meihuaren/personal/DL_logs/ae_denoising64/'\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "\n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            x = tf.placeholder(\"float\", [None, 64]) # 64 original features\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            # ---------------------------------------------\n",
    "            # corrupting (noising) data\n",
    "            # the parameter c is also defined as a placeholder\n",
    "            c = tf.placeholder(tf.float32)\n",
    "            #x_tilde = x*(1.0 - c) + corrupt_x(x)*c\n",
    "            x_tilde = corrupt_x(x)\n",
    "\n",
    "            #define the encoder \n",
    "            code = encoder(x_tilde, int(n_code), phase_train)\n",
    "\n",
    "            #define the decoder\n",
    "            output = decoder(code, int(n_code), phase_train)\n",
    "\n",
    "            #compute the loss \n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "\n",
    "            #save and restore variables to and from checkpoints.\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "\n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            train_writer = tf.summary.FileWriter(model_path, graph=sess.graph)\n",
    "            val_writer   = tf.summary.FileWriter(model_path, graph=sess.graph)\n",
    "\n",
    "            #initialization of the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            sess.run(init_op)\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(x_train.shape[0]/batch_size)\n",
    "                \n",
    "                #train_writer = tf.summary.FileWriter(model_path+str(epoch)+'/model.ckpt', graph=sess.graph)\n",
    "                #val_writer   = tf.summary.FileWriter(model_path+str(epoch)+'/model.ckpt', graph=sess.graph)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    minibatch_x = x_train[i*batch_size:(i+1)*batch_size]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True, c: 1.0})\n",
    "                    \n",
    "                    train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += new_cost/total_batch\n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    \n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "                    train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "\n",
    "                    validation_loss, val_summary = sess.run([eval_op, val_summary_op], feed_dict={x: x_valid, phase_train: False, c: 1.0})\n",
    "                    \n",
    "                    val_writer.add_summary(val_summary, sess.run(global_step))\n",
    "                    \n",
    "                    print(\"Validation Loss:\", validation_loss)\n",
    "\n",
    "                    save_path = saver.save(sess, model_path)\n",
    "                    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "            print(\"Optimization Done\")\n",
    "\n",
    "            test_loss = sess.run(eval_op, feed_dict={x: x_test, phase_train: False, c: 0.0})\n",
    "\n",
    "            print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T13:51:07.293398Z",
     "start_time": "2018-10-02T13:51:07.282274Z"
    }
   },
   "source": [
    "# Main Function - Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Denoising Autoencoder /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/ae_denoising64/\n",
      "Model restored from file: None\n",
      "Running Denoising Autoencoder & Denoising Autoencoder Codes\n",
      "\n",
      "\n",
      "[[4.8222303e-04 9.9868542e-01 7.3421258e-01 ... 9.5275366e-01\n",
      "  1.2876439e-01 9.9984765e-01]\n",
      " [4.7065568e-04 9.9872404e-01 7.2578132e-01 ... 9.9028641e-01\n",
      "  1.7872508e-01 9.9984252e-01]\n",
      " [4.6962066e-04 9.9872524e-01 7.0788687e-01 ... 9.6859497e-01\n",
      "  2.1333012e-01 9.9982446e-01]\n",
      " ...\n",
      " [4.7161992e-04 9.9871993e-01 7.4357194e-01 ... 9.7150427e-01\n",
      "  1.5106350e-01 9.9982917e-01]\n",
      " [1.0040499e-03 9.9746931e-01 7.2965634e-01 ... 9.7775614e-01\n",
      "  1.3465430e-01 9.9984086e-01]\n",
      " [4.7591803e-04 9.9871540e-01 7.9109401e-01 ... 9.5751566e-01\n",
      "  1.3046058e-01 9.9983799e-01]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #feel free to change with your own\n",
    "    args_savepath = '/Users/meihuaren/personal/DL_logs/ae_denoising64/'\n",
    "    new_features_resultpath = '/Users/meihuaren/personal/OR_2018fall/Courses/E4720 Deep Learning/project_coding/Team E_code/'\n",
    "    n_code = 8\n",
    "\n",
    "    #=====================================\n",
    "    # Denoising AutoEncoder\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "            x = tf.placeholder(\"float\", [None, 64]) # 64 original features\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            # ---------------------------------------------\n",
    "            # corrupting (noising) data\n",
    "            # the parameter c is also defined as a placeholder\n",
    "            c = tf.placeholder(tf.float32)\n",
    "            #x_tilde = x*(1.0 - c) + corrupt_x(x)*c\n",
    "            x_tilde = corrupt_x(x)\n",
    "\n",
    "            code = encoder(x_tilde, n_code, phase_train)\n",
    "\n",
    "            output = decoder(code, n_code, phase_train)\n",
    "\n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            #saver = tf.train.Saver()\n",
    "            #sess = tf.Session()\n",
    "            print('\\n')\n",
    "            print('Starting Denoising Autoencoder', args_savepath ) #args.savepath[0]\n",
    "            print('\\n')\n",
    "            \n",
    "            sess = tf.Session()\n",
    "            saver = tf.train.Saver()\n",
    "            save_path = saver.restore(sess, args_savepath ) #args.savepath[0]\n",
    "            print(\"Model restored from file: %s\" % save_path)\n",
    "\n",
    "            print('Running Denoising Autoencoder & Denoising Autoencoder Codes')\n",
    "            print('\\n')\n",
    "            \n",
    "            ae_codes = sess.run(code, feed_dict={x: x_all, phase_train: True, c: 0.0})\n",
    "            print(ae_codes)\n",
    "            ae_codes_df = pd.DataFrame(ae_codes)\n",
    "            features64_new_ae_denoising = pd.concat([ae_codes_df,data.iloc[:,-1]],axis = 1)\n",
    "            filename = new_features_resultpath + 'features64_new_ae_denoising.csv'\n",
    "            features64_new_ae_denoising.to_csv(filename, index=False)\n",
    "            \n",
    "            #ae_codes, ae_reconstruction = sess.run([code, output], feed_dict={x: mnist.test.images*np.random.randint(2, size=(784)), phase_train: True})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
