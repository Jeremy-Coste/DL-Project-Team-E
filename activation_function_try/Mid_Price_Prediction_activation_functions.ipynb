{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTMs to Predict Mid-Price Movement from the Limit Order Book\n",
    "\n",
    "- The goal of this notebook is to predict whether the mid-price will decrease, stay the same, or increase during the next tick. This is accomplished through the usage of an LSTM in tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meihuaren/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from ml_analysis import MLOperator, MLEvaluator, get_LSTM_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_features_new.csv')\n",
    "df = df.dropna()\n",
    "train_weight = 0.8\n",
    "split = int(len(df)*train_weight)\n",
    "df_train = df[:split]\n",
    "df_test = df[split:]\n",
    "operator = MLOperator()\n",
    "n_steps = 5\n",
    "use_features = list(df.columns[:-1])\n",
    "y_train = df_train.label\n",
    "sampled_idx = operator.get_samples_index(y_train.iloc[n_steps-1:], 'min')\n",
    "x_train = df_train[use_features]\n",
    "y_test = df_test.label.iloc[n_steps-1:]\n",
    "x_test = df_test[use_features]\n",
    "x_train, y_train, x_test, y_test = get_LSTM_data(x_train, y_train, x_test, y_test, sampled_idx, n_steps)\n",
    "#normalization\n",
    "x_max = np.max(x_train,axis=0)\n",
    "x_min = np.min(x_train,axis=0)\n",
    "x_train = (x_train - x_min) / (x_max - x_min)\n",
    "x_test = (x_test - x_min) / (x_max - x_min)\n",
    "nrow = 3000\n",
    "x_valid = x_test[0:nrow]\n",
    "y_valid = y_test[0:nrow]\n",
    "x_test = x_test[nrow:]\n",
    "y_test = y_test[nrow:]\n",
    "#print (x_train.shape,y_train.shape,x_test.shape,y_test.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    520883\n",
       "-1      1539\n",
       " 1      1401\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "n_epoch = 5000\n",
    "n_batch = 700\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = x_train.shape[-1] # number of features\n",
    "timesteps = n_steps # timesteps\n",
    "num_hidden = 4 # hidden layer num of features\n",
    "num_classes = 3 # up, down and no-movement\n",
    "\n",
    "# tf Graph input\n",
    "# the input variables are first define as placeholder\n",
    "# a placeholder is a variable/data which will be assigned later\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input]) #dim: batch_size, number of time steps, number of inputs\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])#dim:batch_size, number of classes (10 here)\n",
    "\n",
    "#initialize the weigths with a normal random law initialization\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes], seed = 4720))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes], seed = 4720))\n",
    "}\n",
    "\n",
    "activation_combs = [(i,j) for i in [tf.nn.tanh, tf.nn.sigmoid, tf.nn.relu, tf.nn.elu]\\\n",
    "                          for j in [tf.nn.tanh, tf.nn.sigmoid, tf.nn.relu, tf.nn.elu]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases, activations):\n",
    "    # activations: tuple, element of activation_combs.\n",
    "    \n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "    \n",
    "    with tf.variable_scope(str(activations[0]).split(' ')[1]+'_'+str(activations[1]).split(' ')[1]):\n",
    "\n",
    "        # 1-layer LSTM with num_hidden units\n",
    "        #rnn_cell = rnn.BasicLSTMCell(num_hidden,activation=tf.nn.sigmoid)\n",
    "        #rnn_cell = rnn.BasicLSTMCell(num_hidden)\n",
    "\n",
    "        # 2-layer LSTM, each layer has num_hidden units. And you can wrap more layers together by doing list comprehension.\n",
    "        rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(num_hidden,activation=activations[0]),\\\n",
    "                                     rnn.BasicLSTMCell(num_hidden,activation=activations[1])])\n",
    "\n",
    "        # Get rnn cell output\n",
    "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # (1) Linear activation, using rnn inner loop last output\n",
    "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss and optimzation & Run the model & Evaluation & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using activation combination 1 : tanh + tanh\n",
      "Epoch: 0001 train_loss : 1.2952 train_acc : 0.3333 val_loss : 0.4511 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1030 train_acc : 0.3333 val_loss : 0.8248 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.0272 train_acc : 0.4837 val_loss : 0.6970 val_acc : 0.9810\n",
      "Epoch: 0301 train_loss : 0.9179 train_acc : 0.5560 val_loss : 0.6818 val_acc : 0.9583\n",
      "Epoch: 0401 train_loss : 0.8278 train_acc : 0.6578 val_loss : 0.5853 val_acc : 0.9037\n",
      "Epoch: 0501 train_loss : 0.7348 train_acc : 0.7098 val_loss : 0.4539 val_acc : 0.8120\n",
      "Epoch: 0601 train_loss : 0.6453 train_acc : 0.7470 val_loss : 0.3894 val_acc : 0.7983\n",
      "Epoch: 0701 train_loss : 0.5922 train_acc : 0.7706 val_loss : 0.3643 val_acc : 0.8157\n",
      "Epoch: 0801 train_loss : 0.5605 train_acc : 0.7862 val_loss : 0.3438 val_acc : 0.8333\n",
      "Epoch: 0901 train_loss : 0.5406 train_acc : 0.7934 val_loss : 0.3328 val_acc : 0.8387\n",
      "Epoch: 1001 train_loss : 0.5259 train_acc : 0.7965 val_loss : 0.3247 val_acc : 0.8480\n",
      "Epoch: 1101 train_loss : 0.5153 train_acc : 0.8012 val_loss : 0.3205 val_acc : 0.8513\n",
      "Epoch: 1201 train_loss : 0.5110 train_acc : 0.8040 val_loss : 0.3168 val_acc : 0.8510\n",
      "Epoch: 1301 train_loss : 0.4975 train_acc : 0.8051 val_loss : 0.3198 val_acc : 0.8493\n",
      "Epoch: 1401 train_loss : 0.4919 train_acc : 0.8068 val_loss : 0.3103 val_acc : 0.8560\n",
      "Epoch: 1501 train_loss : 0.4878 train_acc : 0.8087 val_loss : 0.3079 val_acc : 0.8557\n",
      "Epoch: 1601 train_loss : 0.4802 train_acc : 0.8093 val_loss : 0.3043 val_acc : 0.8557\n",
      "Epoch: 1701 train_loss : 0.4724 train_acc : 0.8098 val_loss : 0.3044 val_acc : 0.8520\n",
      "Epoch: 1801 train_loss : 0.4699 train_acc : 0.8123 val_loss : 0.2975 val_acc : 0.8570\n",
      "Epoch: 1901 train_loss : 0.4619 train_acc : 0.8140 val_loss : 0.2918 val_acc : 0.8613\n",
      "Epoch: 2001 train_loss : 0.4628 train_acc : 0.8165 val_loss : 0.2871 val_acc : 0.8637\n",
      "Epoch: 2101 train_loss : 0.4568 train_acc : 0.8179 val_loss : 0.2863 val_acc : 0.8653\n",
      "Epoch: 2201 train_loss : 0.4560 train_acc : 0.8185 val_loss : 0.2820 val_acc : 0.8663\n",
      "Epoch: 2301 train_loss : 0.4494 train_acc : 0.8207 val_loss : 0.2792 val_acc : 0.8703\n",
      "Epoch: 2401 train_loss : 0.4466 train_acc : 0.8212 val_loss : 0.2771 val_acc : 0.8717\n",
      "Epoch: 2501 train_loss : 0.4423 train_acc : 0.8207 val_loss : 0.2791 val_acc : 0.8747\n",
      "Epoch: 2601 train_loss : 0.4387 train_acc : 0.8212 val_loss : 0.2737 val_acc : 0.8770\n",
      "Epoch: 2701 train_loss : 0.4388 train_acc : 0.8235 val_loss : 0.2686 val_acc : 0.8777\n",
      "Epoch: 2801 train_loss : 0.4326 train_acc : 0.8249 val_loss : 0.2647 val_acc : 0.8790\n",
      "Epoch: 2901 train_loss : 0.4324 train_acc : 0.8265 val_loss : 0.2612 val_acc : 0.8767\n",
      "Epoch: 3001 train_loss : 0.4254 train_acc : 0.8276 val_loss : 0.2544 val_acc : 0.8773\n",
      "Epoch: 3101 train_loss : 0.4246 train_acc : 0.8290 val_loss : 0.2501 val_acc : 0.8800\n",
      "Epoch: 3201 train_loss : 0.4240 train_acc : 0.8293 val_loss : 0.2507 val_acc : 0.8783\n",
      "Epoch: 3301 train_loss : 0.4230 train_acc : 0.8307 val_loss : 0.2484 val_acc : 0.8790\n",
      "Epoch: 3401 train_loss : 0.4189 train_acc : 0.8321 val_loss : 0.2457 val_acc : 0.8810\n",
      "Epoch: 3501 train_loss : 0.4203 train_acc : 0.8338 val_loss : 0.2455 val_acc : 0.8817\n",
      "Epoch: 3601 train_loss : 0.4184 train_acc : 0.8346 val_loss : 0.2453 val_acc : 0.8827\n",
      "Epoch: 3701 train_loss : 0.4158 train_acc : 0.8376 val_loss : 0.2438 val_acc : 0.8830\n",
      "Epoch: 3801 train_loss : 0.4128 train_acc : 0.8365 val_loss : 0.2368 val_acc : 0.8853\n",
      "Epoch: 3901 train_loss : 0.4081 train_acc : 0.8382 val_loss : 0.2405 val_acc : 0.8853\n",
      "Epoch: 4001 train_loss : 0.4100 train_acc : 0.8396 val_loss : 0.2427 val_acc : 0.8853\n",
      "Epoch: 4101 train_loss : 0.4091 train_acc : 0.8382 val_loss : 0.2359 val_acc : 0.8873\n",
      "Epoch: 4201 train_loss : 0.4032 train_acc : 0.8390 val_loss : 0.2374 val_acc : 0.8873\n",
      "Epoch: 4301 train_loss : 0.4070 train_acc : 0.8399 val_loss : 0.2411 val_acc : 0.8867\n",
      "Epoch: 4401 train_loss : 0.4068 train_acc : 0.8385 val_loss : 0.2362 val_acc : 0.8883\n",
      "Epoch: 4501 train_loss : 0.4046 train_acc : 0.8399 val_loss : 0.2374 val_acc : 0.8887\n",
      "Epoch: 4601 train_loss : 0.4005 train_acc : 0.8404 val_loss : 0.2336 val_acc : 0.8897\n",
      "Epoch: 4701 train_loss : 0.3982 train_acc : 0.8415 val_loss : 0.2357 val_acc : 0.8897\n",
      "Epoch: 4801 train_loss : 0.3981 train_acc : 0.8413 val_loss : 0.2337 val_acc : 0.8903\n",
      "Epoch: 4901 train_loss : 0.3960 train_acc : 0.8424 val_loss : 0.2341 val_acc : 0.8907\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.8124232\n",
      "Execution time (seconds) was 114.932\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/1/\n",
      "[0.8373591  0.86715196 0.82961783]\n",
      "[0.02697529 0.89643652 0.03491332]\n",
      "Using activation combination 2 : tanh + sigmoid\n",
      "Epoch: 0001 train_loss : 1.1324 train_acc : 0.3350 val_loss : 0.9351 val_acc : 0.6870\n",
      "Epoch: 0101 train_loss : 1.0795 train_acc : 0.4523 val_loss : 0.9230 val_acc : 0.8787\n",
      "Epoch: 0201 train_loss : 0.9918 train_acc : 0.5888 val_loss : 0.8172 val_acc : 0.8300\n",
      "Epoch: 0301 train_loss : 0.8967 train_acc : 0.6792 val_loss : 0.7429 val_acc : 0.8023\n",
      "Epoch: 0401 train_loss : 0.8067 train_acc : 0.7301 val_loss : 0.6556 val_acc : 0.8140\n",
      "Epoch: 0501 train_loss : 0.7374 train_acc : 0.7659 val_loss : 0.5793 val_acc : 0.8253\n",
      "Epoch: 0601 train_loss : 0.6852 train_acc : 0.7826 val_loss : 0.5151 val_acc : 0.8320\n",
      "Epoch: 0701 train_loss : 0.6515 train_acc : 0.7940 val_loss : 0.4663 val_acc : 0.8390\n",
      "Epoch: 0801 train_loss : 0.6239 train_acc : 0.8026 val_loss : 0.4271 val_acc : 0.8457\n",
      "Epoch: 0901 train_loss : 0.6040 train_acc : 0.8071 val_loss : 0.3937 val_acc : 0.8510\n",
      "Epoch: 1001 train_loss : 0.5825 train_acc : 0.8076 val_loss : 0.3698 val_acc : 0.8660\n",
      "Epoch: 1101 train_loss : 0.5708 train_acc : 0.8093 val_loss : 0.3498 val_acc : 0.8737\n",
      "Epoch: 1201 train_loss : 0.5589 train_acc : 0.8107 val_loss : 0.3330 val_acc : 0.8777\n",
      "Epoch: 1301 train_loss : 0.5454 train_acc : 0.8104 val_loss : 0.3205 val_acc : 0.8793\n",
      "Epoch: 1401 train_loss : 0.5339 train_acc : 0.8123 val_loss : 0.3078 val_acc : 0.8823\n",
      "Epoch: 1501 train_loss : 0.5287 train_acc : 0.8140 val_loss : 0.3002 val_acc : 0.8823\n",
      "Epoch: 1601 train_loss : 0.5183 train_acc : 0.8151 val_loss : 0.2894 val_acc : 0.8863\n",
      "Epoch: 1701 train_loss : 0.5117 train_acc : 0.8148 val_loss : 0.2752 val_acc : 0.8910\n",
      "Epoch: 1801 train_loss : 0.5094 train_acc : 0.8171 val_loss : 0.2622 val_acc : 0.8940\n",
      "Epoch: 1901 train_loss : 0.4959 train_acc : 0.8182 val_loss : 0.2518 val_acc : 0.9007\n",
      "Epoch: 2001 train_loss : 0.4926 train_acc : 0.8196 val_loss : 0.2459 val_acc : 0.9023\n",
      "Epoch: 2101 train_loss : 0.4925 train_acc : 0.8187 val_loss : 0.2427 val_acc : 0.9030\n",
      "Epoch: 2201 train_loss : 0.4864 train_acc : 0.8185 val_loss : 0.2389 val_acc : 0.9037\n",
      "Epoch: 2301 train_loss : 0.4793 train_acc : 0.8190 val_loss : 0.2354 val_acc : 0.9047\n",
      "Epoch: 2401 train_loss : 0.4780 train_acc : 0.8193 val_loss : 0.2306 val_acc : 0.9060\n",
      "Epoch: 2501 train_loss : 0.4722 train_acc : 0.8176 val_loss : 0.2286 val_acc : 0.8970\n",
      "Epoch: 2601 train_loss : 0.4696 train_acc : 0.8201 val_loss : 0.2248 val_acc : 0.8920\n",
      "Epoch: 2701 train_loss : 0.4643 train_acc : 0.8201 val_loss : 0.2273 val_acc : 0.8913\n",
      "Epoch: 2801 train_loss : 0.4575 train_acc : 0.8212 val_loss : 0.2254 val_acc : 0.8913\n",
      "Epoch: 2901 train_loss : 0.4551 train_acc : 0.8224 val_loss : 0.2238 val_acc : 0.8917\n",
      "Epoch: 3001 train_loss : 0.4485 train_acc : 0.8243 val_loss : 0.2234 val_acc : 0.8913\n",
      "Epoch: 3101 train_loss : 0.4470 train_acc : 0.8282 val_loss : 0.2180 val_acc : 0.8937\n",
      "Epoch: 3201 train_loss : 0.4421 train_acc : 0.8307 val_loss : 0.2149 val_acc : 0.8973\n",
      "Epoch: 3301 train_loss : 0.4437 train_acc : 0.8312 val_loss : 0.2149 val_acc : 0.8973\n",
      "Epoch: 3401 train_loss : 0.4378 train_acc : 0.8324 val_loss : 0.2126 val_acc : 0.9003\n",
      "Epoch: 3501 train_loss : 0.4329 train_acc : 0.8335 val_loss : 0.2064 val_acc : 0.9037\n",
      "Epoch: 3601 train_loss : 0.4330 train_acc : 0.8354 val_loss : 0.2063 val_acc : 0.9040\n",
      "Epoch: 3701 train_loss : 0.4304 train_acc : 0.8363 val_loss : 0.2073 val_acc : 0.9030\n",
      "Epoch: 3801 train_loss : 0.4276 train_acc : 0.8363 val_loss : 0.2057 val_acc : 0.9053\n",
      "Epoch: 3901 train_loss : 0.4243 train_acc : 0.8371 val_loss : 0.2036 val_acc : 0.9073\n",
      "Epoch: 4001 train_loss : 0.4232 train_acc : 0.8376 val_loss : 0.2013 val_acc : 0.9077\n",
      "Epoch: 4101 train_loss : 0.4195 train_acc : 0.8379 val_loss : 0.2044 val_acc : 0.9073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4201 train_loss : 0.4170 train_acc : 0.8379 val_loss : 0.1972 val_acc : 0.9090\n",
      "Epoch: 4301 train_loss : 0.4193 train_acc : 0.8376 val_loss : 0.1995 val_acc : 0.9080\n",
      "Epoch: 4401 train_loss : 0.4113 train_acc : 0.8385 val_loss : 0.2012 val_acc : 0.9067\n",
      "Epoch: 4501 train_loss : 0.4113 train_acc : 0.8382 val_loss : 0.1982 val_acc : 0.9077\n",
      "Epoch: 4601 train_loss : 0.4118 train_acc : 0.8401 val_loss : 0.1959 val_acc : 0.9083\n",
      "Epoch: 4701 train_loss : 0.4059 train_acc : 0.8413 val_loss : 0.1968 val_acc : 0.9080\n",
      "Epoch: 4801 train_loss : 0.4081 train_acc : 0.8421 val_loss : 0.1950 val_acc : 0.9073\n",
      "Epoch: 4901 train_loss : 0.4042 train_acc : 0.8438 val_loss : 0.1920 val_acc : 0.9083\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.8264856\n",
      "Execution time (seconds) was 114.652\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/2/\n",
      "[0.8409725  0.86425339 0.83151515]\n",
      "[0.02869229 0.90494342 0.03848224]\n",
      "Using activation combination 3 : tanh + relu\n",
      "Epoch: 0001 train_loss : 1.2355 train_acc : 0.3333 val_loss : 0.5547 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0066 train_acc : 0.5377 val_loss : 1.0244 val_acc : 0.4170\n",
      "Epoch: 0201 train_loss : 0.8619 train_acc : 0.6333 val_loss : 0.8562 val_acc : 0.6557\n",
      "Epoch: 0301 train_loss : 0.7740 train_acc : 0.6953 val_loss : 0.7442 val_acc : 0.7667\n",
      "Epoch: 0401 train_loss : 0.7120 train_acc : 0.7389 val_loss : 0.6990 val_acc : 0.7813\n",
      "Epoch: 0501 train_loss : 0.6743 train_acc : 0.7587 val_loss : 0.6635 val_acc : 0.8030\n",
      "Epoch: 0601 train_loss : 0.6415 train_acc : 0.7723 val_loss : 0.6252 val_acc : 0.8230\n",
      "Epoch: 0701 train_loss : 0.6154 train_acc : 0.7812 val_loss : 0.5774 val_acc : 0.8397\n",
      "Epoch: 0801 train_loss : 0.5923 train_acc : 0.7882 val_loss : 0.5301 val_acc : 0.8567\n",
      "Epoch: 0901 train_loss : 0.5580 train_acc : 0.7959 val_loss : 0.3936 val_acc : 0.8713\n",
      "Epoch: 1001 train_loss : 0.5185 train_acc : 0.8001 val_loss : 0.2816 val_acc : 0.8797\n",
      "Epoch: 1101 train_loss : 0.4988 train_acc : 0.8046 val_loss : 0.2492 val_acc : 0.8817\n",
      "Epoch: 1201 train_loss : 0.4846 train_acc : 0.8093 val_loss : 0.2416 val_acc : 0.8830\n",
      "Epoch: 1301 train_loss : 0.4739 train_acc : 0.8101 val_loss : 0.2389 val_acc : 0.8840\n",
      "Epoch: 1401 train_loss : 0.4682 train_acc : 0.8115 val_loss : 0.2386 val_acc : 0.8863\n",
      "Epoch: 1501 train_loss : 0.4622 train_acc : 0.8132 val_loss : 0.2341 val_acc : 0.8870\n",
      "Epoch: 1601 train_loss : 0.4558 train_acc : 0.8171 val_loss : 0.2314 val_acc : 0.8887\n",
      "Epoch: 1701 train_loss : 0.4533 train_acc : 0.8196 val_loss : 0.2305 val_acc : 0.8913\n",
      "Epoch: 1801 train_loss : 0.4463 train_acc : 0.8204 val_loss : 0.2355 val_acc : 0.8927\n",
      "Epoch: 1901 train_loss : 0.4366 train_acc : 0.8221 val_loss : 0.2311 val_acc : 0.8957\n",
      "Epoch: 2001 train_loss : 0.4356 train_acc : 0.8232 val_loss : 0.2364 val_acc : 0.8967\n",
      "Epoch: 2101 train_loss : 0.4375 train_acc : 0.8254 val_loss : 0.2354 val_acc : 0.8973\n",
      "Epoch: 2201 train_loss : 0.4297 train_acc : 0.8268 val_loss : 0.2359 val_acc : 0.8977\n",
      "Epoch: 2301 train_loss : 0.4277 train_acc : 0.8276 val_loss : 0.2359 val_acc : 0.8980\n",
      "Epoch: 2401 train_loss : 0.4274 train_acc : 0.8282 val_loss : 0.2380 val_acc : 0.8977\n",
      "Epoch: 2501 train_loss : 0.4235 train_acc : 0.8307 val_loss : 0.2403 val_acc : 0.8967\n",
      "Epoch: 2601 train_loss : 0.4194 train_acc : 0.8332 val_loss : 0.2451 val_acc : 0.8960\n",
      "Epoch: 2701 train_loss : 0.4177 train_acc : 0.8338 val_loss : 0.2415 val_acc : 0.8960\n",
      "Epoch: 2801 train_loss : 0.4134 train_acc : 0.8338 val_loss : 0.2445 val_acc : 0.8953\n",
      "Epoch: 2901 train_loss : 0.4124 train_acc : 0.8346 val_loss : 0.2415 val_acc : 0.8950\n",
      "Epoch: 3001 train_loss : 0.4064 train_acc : 0.8368 val_loss : 0.2453 val_acc : 0.8950\n",
      "Epoch: 3101 train_loss : 0.4019 train_acc : 0.8396 val_loss : 0.2449 val_acc : 0.8943\n",
      "Epoch: 3201 train_loss : 0.4029 train_acc : 0.8396 val_loss : 0.2490 val_acc : 0.8930\n",
      "Epoch: 3301 train_loss : 0.3991 train_acc : 0.8418 val_loss : 0.2448 val_acc : 0.8957\n",
      "Epoch: 3401 train_loss : 0.3946 train_acc : 0.8415 val_loss : 0.2477 val_acc : 0.8950\n",
      "Epoch: 3501 train_loss : 0.3940 train_acc : 0.8429 val_loss : 0.2464 val_acc : 0.8963\n",
      "Epoch: 3601 train_loss : 0.3941 train_acc : 0.8438 val_loss : 0.2473 val_acc : 0.8967\n",
      "Epoch: 3701 train_loss : 0.3923 train_acc : 0.8438 val_loss : 0.2466 val_acc : 0.8967\n",
      "Epoch: 3801 train_loss : 0.3891 train_acc : 0.8432 val_loss : 0.2464 val_acc : 0.8963\n",
      "Epoch: 3901 train_loss : 0.3858 train_acc : 0.8429 val_loss : 0.2457 val_acc : 0.8937\n",
      "Epoch: 4001 train_loss : 0.3842 train_acc : 0.8438 val_loss : 0.2487 val_acc : 0.8930\n",
      "Epoch: 4101 train_loss : 0.3816 train_acc : 0.8432 val_loss : 0.2450 val_acc : 0.8930\n",
      "Epoch: 4201 train_loss : 0.3823 train_acc : 0.8435 val_loss : 0.2471 val_acc : 0.8920\n",
      "Epoch: 4301 train_loss : 0.3818 train_acc : 0.8446 val_loss : 0.2446 val_acc : 0.8940\n",
      "Epoch: 4401 train_loss : 0.3797 train_acc : 0.8457 val_loss : 0.2459 val_acc : 0.8930\n",
      "Epoch: 4501 train_loss : 0.3756 train_acc : 0.8468 val_loss : 0.2366 val_acc : 0.8973\n",
      "Epoch: 4601 train_loss : 0.3739 train_acc : 0.8479 val_loss : 0.2482 val_acc : 0.8920\n",
      "Epoch: 4701 train_loss : 0.3733 train_acc : 0.8479 val_loss : 0.2439 val_acc : 0.8950\n",
      "Epoch: 4801 train_loss : 0.3694 train_acc : 0.8479 val_loss : 0.2476 val_acc : 0.8943\n",
      "Epoch: 4901 train_loss : 0.3711 train_acc : 0.8493 val_loss : 0.2503 val_acc : 0.8927\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.815843\n",
      "Execution time (seconds) was 115.075\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/3/\n",
      "[0.84295519 0.86590389 0.84123223]\n",
      "[0.03049232 0.8985216  0.03213174]\n",
      "Using activation combination 4 : tanh + elu\n",
      "Epoch: 0001 train_loss : 1.3046 train_acc : 0.3333 val_loss : 0.4937 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0904 train_acc : 0.3522 val_loss : 0.8382 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 0.9470 train_acc : 0.5591 val_loss : 1.0466 val_acc : 0.2257\n",
      "Epoch: 0301 train_loss : 0.8416 train_acc : 0.6486 val_loss : 0.8135 val_acc : 0.6837\n",
      "Epoch: 0401 train_loss : 0.7595 train_acc : 0.7117 val_loss : 0.6739 val_acc : 0.7990\n",
      "Epoch: 0501 train_loss : 0.6810 train_acc : 0.7409 val_loss : 0.5038 val_acc : 0.8320\n",
      "Epoch: 0601 train_loss : 0.6147 train_acc : 0.7645 val_loss : 0.4065 val_acc : 0.8307\n",
      "Epoch: 0701 train_loss : 0.5584 train_acc : 0.7857 val_loss : 0.3825 val_acc : 0.8263\n",
      "Epoch: 0801 train_loss : 0.5335 train_acc : 0.7957 val_loss : 0.3774 val_acc : 0.8257\n",
      "Epoch: 0901 train_loss : 0.5103 train_acc : 0.7993 val_loss : 0.3688 val_acc : 0.8290\n",
      "Epoch: 1001 train_loss : 0.5000 train_acc : 0.8018 val_loss : 0.3639 val_acc : 0.8347\n",
      "Epoch: 1101 train_loss : 0.4917 train_acc : 0.8040 val_loss : 0.3538 val_acc : 0.8403\n",
      "Epoch: 1201 train_loss : 0.4831 train_acc : 0.8071 val_loss : 0.3487 val_acc : 0.8423\n",
      "Epoch: 1301 train_loss : 0.4765 train_acc : 0.8073 val_loss : 0.3391 val_acc : 0.8450\n",
      "Epoch: 1401 train_loss : 0.4713 train_acc : 0.8093 val_loss : 0.3321 val_acc : 0.8450\n",
      "Epoch: 1501 train_loss : 0.4698 train_acc : 0.8110 val_loss : 0.3184 val_acc : 0.8480\n",
      "Epoch: 1601 train_loss : 0.4611 train_acc : 0.8121 val_loss : 0.3183 val_acc : 0.8480\n",
      "Epoch: 1701 train_loss : 0.4600 train_acc : 0.8126 val_loss : 0.3115 val_acc : 0.8517\n",
      "Epoch: 1801 train_loss : 0.4574 train_acc : 0.8143 val_loss : 0.3036 val_acc : 0.8590\n",
      "Epoch: 1901 train_loss : 0.4582 train_acc : 0.8168 val_loss : 0.3028 val_acc : 0.8610\n",
      "Epoch: 2001 train_loss : 0.4498 train_acc : 0.8165 val_loss : 0.3001 val_acc : 0.8613\n",
      "Epoch: 2101 train_loss : 0.4493 train_acc : 0.8193 val_loss : 0.2957 val_acc : 0.8617\n",
      "Epoch: 2201 train_loss : 0.4466 train_acc : 0.8215 val_loss : 0.2852 val_acc : 0.8653\n",
      "Epoch: 2301 train_loss : 0.4430 train_acc : 0.8232 val_loss : 0.2889 val_acc : 0.8623\n",
      "Epoch: 2401 train_loss : 0.4447 train_acc : 0.8235 val_loss : 0.2813 val_acc : 0.8657\n",
      "Epoch: 2501 train_loss : 0.4387 train_acc : 0.8249 val_loss : 0.2835 val_acc : 0.8633\n",
      "Epoch: 2601 train_loss : 0.4371 train_acc : 0.8265 val_loss : 0.2753 val_acc : 0.8663\n",
      "Epoch: 2701 train_loss : 0.4349 train_acc : 0.8276 val_loss : 0.2779 val_acc : 0.8630\n",
      "Epoch: 2801 train_loss : 0.4331 train_acc : 0.8279 val_loss : 0.2718 val_acc : 0.8653\n",
      "Epoch: 2901 train_loss : 0.4284 train_acc : 0.8285 val_loss : 0.2689 val_acc : 0.8650\n",
      "Epoch: 3001 train_loss : 0.4297 train_acc : 0.8282 val_loss : 0.2662 val_acc : 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3101 train_loss : 0.4278 train_acc : 0.8299 val_loss : 0.2616 val_acc : 0.8663\n",
      "Epoch: 3201 train_loss : 0.4243 train_acc : 0.8296 val_loss : 0.2592 val_acc : 0.8667\n",
      "Epoch: 3301 train_loss : 0.4236 train_acc : 0.8282 val_loss : 0.2545 val_acc : 0.8680\n",
      "Epoch: 3401 train_loss : 0.4230 train_acc : 0.8296 val_loss : 0.2473 val_acc : 0.8723\n",
      "Epoch: 3501 train_loss : 0.4171 train_acc : 0.8301 val_loss : 0.2480 val_acc : 0.8723\n",
      "Epoch: 3601 train_loss : 0.4153 train_acc : 0.8307 val_loss : 0.2390 val_acc : 0.8740\n",
      "Epoch: 3701 train_loss : 0.4155 train_acc : 0.8318 val_loss : 0.2350 val_acc : 0.8753\n",
      "Epoch: 3801 train_loss : 0.4149 train_acc : 0.8335 val_loss : 0.2311 val_acc : 0.8763\n",
      "Epoch: 3901 train_loss : 0.4111 train_acc : 0.8340 val_loss : 0.2260 val_acc : 0.8793\n",
      "Epoch: 4001 train_loss : 0.4101 train_acc : 0.8346 val_loss : 0.2246 val_acc : 0.8793\n",
      "Epoch: 4101 train_loss : 0.4086 train_acc : 0.8354 val_loss : 0.2191 val_acc : 0.8813\n",
      "Epoch: 4201 train_loss : 0.4041 train_acc : 0.8351 val_loss : 0.2225 val_acc : 0.8793\n",
      "Epoch: 4301 train_loss : 0.4066 train_acc : 0.8368 val_loss : 0.2151 val_acc : 0.8823\n",
      "Epoch: 4401 train_loss : 0.4027 train_acc : 0.8368 val_loss : 0.2182 val_acc : 0.8810\n",
      "Epoch: 4501 train_loss : 0.4012 train_acc : 0.8368 val_loss : 0.2154 val_acc : 0.8830\n",
      "Epoch: 4601 train_loss : 0.4004 train_acc : 0.8371 val_loss : 0.2183 val_acc : 0.8820\n",
      "Epoch: 4701 train_loss : 0.3965 train_acc : 0.8371 val_loss : 0.2175 val_acc : 0.8830\n",
      "Epoch: 4801 train_loss : 0.3950 train_acc : 0.8368 val_loss : 0.2185 val_acc : 0.8827\n",
      "Epoch: 4901 train_loss : 0.3954 train_acc : 0.8396 val_loss : 0.2197 val_acc : 0.8813\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.81560713\n",
      "Execution time (seconds) was 115.065\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/4/\n",
      "[0.82861635 0.85960927 0.83054308]\n",
      "[0.02343344 0.89848744 0.04127199]\n",
      "Using activation combination 5 : sigmoid + tanh\n",
      "Epoch: 0001 train_loss : 1.3327 train_acc : 0.3333 val_loss : 0.5070 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1545 train_acc : 0.3728 val_loss : 0.8275 val_acc : 0.9743\n",
      "Epoch: 0201 train_loss : 1.0981 train_acc : 0.4448 val_loss : 0.9536 val_acc : 0.7453\n",
      "Epoch: 0301 train_loss : 1.0674 train_acc : 0.4618 val_loss : 0.9076 val_acc : 0.9123\n",
      "Epoch: 0401 train_loss : 1.0316 train_acc : 0.4846 val_loss : 0.7819 val_acc : 0.9620\n",
      "Epoch: 0501 train_loss : 0.9820 train_acc : 0.5299 val_loss : 0.7267 val_acc : 0.8990\n",
      "Epoch: 0601 train_loss : 0.9076 train_acc : 0.5919 val_loss : 0.7237 val_acc : 0.8563\n",
      "Epoch: 0701 train_loss : 0.8151 train_acc : 0.6569 val_loss : 0.6609 val_acc : 0.8437\n",
      "Epoch: 0801 train_loss : 0.7434 train_acc : 0.7267 val_loss : 0.5549 val_acc : 0.8440\n",
      "Epoch: 0901 train_loss : 0.6933 train_acc : 0.7526 val_loss : 0.4746 val_acc : 0.8453\n",
      "Epoch: 1001 train_loss : 0.6515 train_acc : 0.7659 val_loss : 0.4079 val_acc : 0.8447\n",
      "Epoch: 1101 train_loss : 0.6272 train_acc : 0.7729 val_loss : 0.3570 val_acc : 0.8487\n",
      "Epoch: 1201 train_loss : 0.6064 train_acc : 0.7820 val_loss : 0.3194 val_acc : 0.8530\n",
      "Epoch: 1301 train_loss : 0.5875 train_acc : 0.7851 val_loss : 0.2970 val_acc : 0.8563\n",
      "Epoch: 1401 train_loss : 0.5764 train_acc : 0.7882 val_loss : 0.2855 val_acc : 0.8567\n",
      "Epoch: 1501 train_loss : 0.5647 train_acc : 0.7912 val_loss : 0.2741 val_acc : 0.8607\n",
      "Epoch: 1601 train_loss : 0.5560 train_acc : 0.7932 val_loss : 0.2663 val_acc : 0.8643\n",
      "Epoch: 1701 train_loss : 0.5465 train_acc : 0.7968 val_loss : 0.2629 val_acc : 0.8637\n",
      "Epoch: 1801 train_loss : 0.5398 train_acc : 0.7973 val_loss : 0.2606 val_acc : 0.8627\n",
      "Epoch: 1901 train_loss : 0.5259 train_acc : 0.7996 val_loss : 0.2616 val_acc : 0.8580\n",
      "Epoch: 2001 train_loss : 0.5159 train_acc : 0.8004 val_loss : 0.2665 val_acc : 0.8520\n",
      "Epoch: 2101 train_loss : 0.5087 train_acc : 0.8012 val_loss : 0.2688 val_acc : 0.8480\n",
      "Epoch: 2201 train_loss : 0.5047 train_acc : 0.8037 val_loss : 0.2694 val_acc : 0.8480\n",
      "Epoch: 2301 train_loss : 0.4973 train_acc : 0.8046 val_loss : 0.2694 val_acc : 0.8480\n",
      "Epoch: 2401 train_loss : 0.4899 train_acc : 0.8068 val_loss : 0.2718 val_acc : 0.8473\n",
      "Epoch: 2501 train_loss : 0.4871 train_acc : 0.8082 val_loss : 0.2748 val_acc : 0.8460\n",
      "Epoch: 2601 train_loss : 0.4821 train_acc : 0.8082 val_loss : 0.2746 val_acc : 0.8467\n",
      "Epoch: 2701 train_loss : 0.4792 train_acc : 0.8110 val_loss : 0.2775 val_acc : 0.8460\n",
      "Epoch: 2801 train_loss : 0.4778 train_acc : 0.8115 val_loss : 0.2783 val_acc : 0.8460\n",
      "Epoch: 2901 train_loss : 0.4727 train_acc : 0.8123 val_loss : 0.2807 val_acc : 0.8453\n",
      "Epoch: 3001 train_loss : 0.4704 train_acc : 0.8137 val_loss : 0.2809 val_acc : 0.8453\n",
      "Epoch: 3101 train_loss : 0.4671 train_acc : 0.8151 val_loss : 0.2843 val_acc : 0.8447\n",
      "Epoch: 3201 train_loss : 0.4634 train_acc : 0.8162 val_loss : 0.2852 val_acc : 0.8457\n",
      "Epoch: 3301 train_loss : 0.4605 train_acc : 0.8151 val_loss : 0.2906 val_acc : 0.8447\n",
      "Epoch: 3401 train_loss : 0.4602 train_acc : 0.8171 val_loss : 0.2895 val_acc : 0.8457\n",
      "Epoch: 3501 train_loss : 0.4579 train_acc : 0.8176 val_loss : 0.2927 val_acc : 0.8457\n",
      "Epoch: 3601 train_loss : 0.4520 train_acc : 0.8190 val_loss : 0.2914 val_acc : 0.8470\n",
      "Epoch: 3701 train_loss : 0.4590 train_acc : 0.8198 val_loss : 0.2975 val_acc : 0.8460\n",
      "Epoch: 3801 train_loss : 0.4522 train_acc : 0.8212 val_loss : 0.2936 val_acc : 0.8473\n",
      "Epoch: 3901 train_loss : 0.4486 train_acc : 0.8215 val_loss : 0.2996 val_acc : 0.8460\n",
      "Epoch: 4001 train_loss : 0.4482 train_acc : 0.8226 val_loss : 0.2981 val_acc : 0.8477\n",
      "Epoch: 4101 train_loss : 0.4429 train_acc : 0.8240 val_loss : 0.3013 val_acc : 0.8470\n",
      "Epoch: 4201 train_loss : 0.4454 train_acc : 0.8232 val_loss : 0.3042 val_acc : 0.8473\n",
      "Epoch: 4301 train_loss : 0.4461 train_acc : 0.8232 val_loss : 0.3003 val_acc : 0.8480\n",
      "Epoch: 4401 train_loss : 0.4406 train_acc : 0.8237 val_loss : 0.3040 val_acc : 0.8480\n",
      "Epoch: 4501 train_loss : 0.4421 train_acc : 0.8243 val_loss : 0.3059 val_acc : 0.8477\n",
      "Epoch: 4601 train_loss : 0.4370 train_acc : 0.8240 val_loss : 0.3062 val_acc : 0.8480\n",
      "Epoch: 4701 train_loss : 0.4371 train_acc : 0.8257 val_loss : 0.3028 val_acc : 0.8487\n",
      "Epoch: 4801 train_loss : 0.4335 train_acc : 0.8257 val_loss : 0.3083 val_acc : 0.8470\n",
      "Epoch: 4901 train_loss : 0.4339 train_acc : 0.8262 val_loss : 0.3036 val_acc : 0.8480\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7921011\n",
      "Execution time (seconds) was 116.431\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/5/\n",
      "[0.82023346 0.8496732  0.81466559]\n",
      "[0.03221957 0.88388812 0.02693774]\n",
      "Using activation combination 6 : sigmoid + sigmoid\n",
      "Epoch: 0001 train_loss : 1.1276 train_acc : 0.3333 val_loss : 1.0340 val_acc : 0.0027\n",
      "Epoch: 0101 train_loss : 1.0984 train_acc : 0.3333 val_loss : 1.0694 val_acc : 0.0027\n",
      "Epoch: 0201 train_loss : 1.0901 train_acc : 0.3878 val_loss : 1.0808 val_acc : 0.1923\n",
      "Epoch: 0301 train_loss : 1.0802 train_acc : 0.5660 val_loss : 1.0581 val_acc : 0.9117\n",
      "Epoch: 0401 train_loss : 1.0639 train_acc : 0.5841 val_loss : 1.0178 val_acc : 0.9860\n",
      "Epoch: 0501 train_loss : 1.0397 train_acc : 0.6072 val_loss : 0.9744 val_acc : 0.9713\n",
      "Epoch: 0601 train_loss : 1.0068 train_acc : 0.6286 val_loss : 0.9365 val_acc : 0.9120\n",
      "Epoch: 0701 train_loss : 0.9668 train_acc : 0.6542 val_loss : 0.9069 val_acc : 0.8483\n",
      "Epoch: 0801 train_loss : 0.9233 train_acc : 0.6675 val_loss : 0.8770 val_acc : 0.8003\n",
      "Epoch: 0901 train_loss : 0.8843 train_acc : 0.6764 val_loss : 0.8422 val_acc : 0.7810\n",
      "Epoch: 1001 train_loss : 0.8501 train_acc : 0.6906 val_loss : 0.7968 val_acc : 0.7863\n",
      "Epoch: 1101 train_loss : 0.8194 train_acc : 0.7075 val_loss : 0.7458 val_acc : 0.8090\n",
      "Epoch: 1201 train_loss : 0.7908 train_acc : 0.7181 val_loss : 0.6940 val_acc : 0.8207\n",
      "Epoch: 1301 train_loss : 0.7643 train_acc : 0.7337 val_loss : 0.6436 val_acc : 0.8333\n",
      "Epoch: 1401 train_loss : 0.7345 train_acc : 0.7453 val_loss : 0.6002 val_acc : 0.8337\n",
      "Epoch: 1501 train_loss : 0.7124 train_acc : 0.7567 val_loss : 0.5621 val_acc : 0.8343\n",
      "Epoch: 1601 train_loss : 0.6923 train_acc : 0.7620 val_loss : 0.5308 val_acc : 0.8357\n",
      "Epoch: 1701 train_loss : 0.6693 train_acc : 0.7662 val_loss : 0.5044 val_acc : 0.8367\n",
      "Epoch: 1801 train_loss : 0.6492 train_acc : 0.7740 val_loss : 0.4814 val_acc : 0.8360\n",
      "Epoch: 1901 train_loss : 0.6343 train_acc : 0.7773 val_loss : 0.4620 val_acc : 0.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2001 train_loss : 0.6208 train_acc : 0.7801 val_loss : 0.4459 val_acc : 0.8373\n",
      "Epoch: 2101 train_loss : 0.6039 train_acc : 0.7848 val_loss : 0.4316 val_acc : 0.8377\n",
      "Epoch: 2201 train_loss : 0.5927 train_acc : 0.7887 val_loss : 0.4170 val_acc : 0.8377\n",
      "Epoch: 2301 train_loss : 0.5785 train_acc : 0.7907 val_loss : 0.4045 val_acc : 0.8383\n",
      "Epoch: 2401 train_loss : 0.5681 train_acc : 0.7934 val_loss : 0.3940 val_acc : 0.8377\n",
      "Epoch: 2501 train_loss : 0.5576 train_acc : 0.7968 val_loss : 0.3836 val_acc : 0.8387\n",
      "Epoch: 2601 train_loss : 0.5469 train_acc : 0.8004 val_loss : 0.3740 val_acc : 0.8383\n",
      "Epoch: 2701 train_loss : 0.5415 train_acc : 0.8029 val_loss : 0.3645 val_acc : 0.8387\n",
      "Epoch: 2801 train_loss : 0.5315 train_acc : 0.8046 val_loss : 0.3563 val_acc : 0.8393\n",
      "Epoch: 2901 train_loss : 0.5255 train_acc : 0.8054 val_loss : 0.3475 val_acc : 0.8410\n",
      "Epoch: 3001 train_loss : 0.5180 train_acc : 0.8101 val_loss : 0.3414 val_acc : 0.8417\n",
      "Epoch: 3101 train_loss : 0.5119 train_acc : 0.8112 val_loss : 0.3352 val_acc : 0.8417\n",
      "Epoch: 3201 train_loss : 0.4998 train_acc : 0.8137 val_loss : 0.3298 val_acc : 0.8427\n",
      "Epoch: 3301 train_loss : 0.4972 train_acc : 0.8137 val_loss : 0.3240 val_acc : 0.8443\n",
      "Epoch: 3401 train_loss : 0.4909 train_acc : 0.8154 val_loss : 0.3195 val_acc : 0.8447\n",
      "Epoch: 3501 train_loss : 0.4902 train_acc : 0.8171 val_loss : 0.3162 val_acc : 0.8457\n",
      "Epoch: 3601 train_loss : 0.4832 train_acc : 0.8187 val_loss : 0.3134 val_acc : 0.8463\n",
      "Epoch: 3701 train_loss : 0.4780 train_acc : 0.8207 val_loss : 0.3084 val_acc : 0.8470\n",
      "Epoch: 3801 train_loss : 0.4747 train_acc : 0.8215 val_loss : 0.3070 val_acc : 0.8477\n",
      "Epoch: 3901 train_loss : 0.4738 train_acc : 0.8224 val_loss : 0.3028 val_acc : 0.8493\n",
      "Epoch: 4001 train_loss : 0.4685 train_acc : 0.8235 val_loss : 0.3018 val_acc : 0.8513\n",
      "Epoch: 4101 train_loss : 0.4670 train_acc : 0.8235 val_loss : 0.3004 val_acc : 0.8530\n",
      "Epoch: 4201 train_loss : 0.4625 train_acc : 0.8243 val_loss : 0.2993 val_acc : 0.8540\n",
      "Epoch: 4301 train_loss : 0.4598 train_acc : 0.8243 val_loss : 0.2978 val_acc : 0.8550\n",
      "Epoch: 4401 train_loss : 0.4531 train_acc : 0.8251 val_loss : 0.2954 val_acc : 0.8573\n",
      "Epoch: 4501 train_loss : 0.4530 train_acc : 0.8251 val_loss : 0.2960 val_acc : 0.8590\n",
      "Epoch: 4601 train_loss : 0.4482 train_acc : 0.8257 val_loss : 0.2942 val_acc : 0.8600\n",
      "Epoch: 4701 train_loss : 0.4497 train_acc : 0.8265 val_loss : 0.2928 val_acc : 0.8600\n",
      "Epoch: 4801 train_loss : 0.4463 train_acc : 0.8268 val_loss : 0.2924 val_acc : 0.8603\n",
      "Epoch: 4901 train_loss : 0.4427 train_acc : 0.8265 val_loss : 0.2911 val_acc : 0.8610\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.80751956\n",
      "Execution time (seconds) was 117.256\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/6/\n",
      "[0.81990521 0.84700461 0.81701445]\n",
      "[0.02974732 0.89340755 0.03408687]\n",
      "Using activation combination 7 : sigmoid + relu\n",
      "Epoch: 0001 train_loss : 1.2113 train_acc : 0.3333 val_loss : 0.5933 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0979 train_acc : 0.4128 val_loss : 0.8798 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.0542 train_acc : 0.4976 val_loss : 0.9651 val_acc : 0.9970\n",
      "Epoch: 0301 train_loss : 1.0048 train_acc : 0.5652 val_loss : 0.9070 val_acc : 0.9703\n",
      "Epoch: 0401 train_loss : 0.9209 train_acc : 0.6275 val_loss : 0.8899 val_acc : 0.8420\n",
      "Epoch: 0501 train_loss : 0.8444 train_acc : 0.6455 val_loss : 0.8641 val_acc : 0.7587\n",
      "Epoch: 0601 train_loss : 0.7969 train_acc : 0.6717 val_loss : 0.8204 val_acc : 0.7507\n",
      "Epoch: 0701 train_loss : 0.7702 train_acc : 0.6956 val_loss : 0.7802 val_acc : 0.7687\n",
      "Epoch: 0801 train_loss : 0.7453 train_acc : 0.7109 val_loss : 0.7414 val_acc : 0.7843\n",
      "Epoch: 0901 train_loss : 0.7277 train_acc : 0.7270 val_loss : 0.7045 val_acc : 0.7917\n",
      "Epoch: 1001 train_loss : 0.7082 train_acc : 0.7406 val_loss : 0.6757 val_acc : 0.7980\n",
      "Epoch: 1101 train_loss : 0.6871 train_acc : 0.7465 val_loss : 0.6505 val_acc : 0.8040\n",
      "Epoch: 1201 train_loss : 0.6720 train_acc : 0.7506 val_loss : 0.6281 val_acc : 0.8120\n",
      "Epoch: 1301 train_loss : 0.6587 train_acc : 0.7584 val_loss : 0.6069 val_acc : 0.8187\n",
      "Epoch: 1401 train_loss : 0.6467 train_acc : 0.7615 val_loss : 0.5925 val_acc : 0.8210\n",
      "Epoch: 1501 train_loss : 0.6348 train_acc : 0.7651 val_loss : 0.5676 val_acc : 0.8303\n",
      "Epoch: 1601 train_loss : 0.6236 train_acc : 0.7693 val_loss : 0.5467 val_acc : 0.8350\n",
      "Epoch: 1701 train_loss : 0.6146 train_acc : 0.7718 val_loss : 0.5282 val_acc : 0.8387\n",
      "Epoch: 1801 train_loss : 0.6001 train_acc : 0.7770 val_loss : 0.5068 val_acc : 0.8427\n",
      "Epoch: 1901 train_loss : 0.5961 train_acc : 0.7793 val_loss : 0.4834 val_acc : 0.8507\n",
      "Epoch: 2001 train_loss : 0.5841 train_acc : 0.7823 val_loss : 0.4648 val_acc : 0.8553\n",
      "Epoch: 2101 train_loss : 0.5763 train_acc : 0.7851 val_loss : 0.4460 val_acc : 0.8613\n",
      "Epoch: 2201 train_loss : 0.5623 train_acc : 0.7890 val_loss : 0.4311 val_acc : 0.8647\n",
      "Epoch: 2301 train_loss : 0.5574 train_acc : 0.7904 val_loss : 0.4104 val_acc : 0.8670\n",
      "Epoch: 2401 train_loss : 0.5473 train_acc : 0.7954 val_loss : 0.3967 val_acc : 0.8643\n",
      "Epoch: 2501 train_loss : 0.5373 train_acc : 0.7968 val_loss : 0.3804 val_acc : 0.8667\n",
      "Epoch: 2601 train_loss : 0.5318 train_acc : 0.7982 val_loss : 0.3685 val_acc : 0.8683\n",
      "Epoch: 2701 train_loss : 0.5245 train_acc : 0.7993 val_loss : 0.3572 val_acc : 0.8690\n",
      "Epoch: 2801 train_loss : 0.5183 train_acc : 0.8004 val_loss : 0.3461 val_acc : 0.8713\n",
      "Epoch: 2901 train_loss : 0.5127 train_acc : 0.8012 val_loss : 0.3369 val_acc : 0.8713\n",
      "Epoch: 3001 train_loss : 0.5047 train_acc : 0.8032 val_loss : 0.3292 val_acc : 0.8737\n",
      "Epoch: 3101 train_loss : 0.5025 train_acc : 0.8034 val_loss : 0.3236 val_acc : 0.8747\n",
      "Epoch: 3201 train_loss : 0.4967 train_acc : 0.8043 val_loss : 0.3135 val_acc : 0.8773\n",
      "Epoch: 3301 train_loss : 0.4935 train_acc : 0.8051 val_loss : 0.3079 val_acc : 0.8787\n",
      "Epoch: 3401 train_loss : 0.4898 train_acc : 0.8057 val_loss : 0.3008 val_acc : 0.8800\n",
      "Epoch: 3501 train_loss : 0.4836 train_acc : 0.8054 val_loss : 0.2955 val_acc : 0.8817\n",
      "Epoch: 3601 train_loss : 0.4822 train_acc : 0.8062 val_loss : 0.2905 val_acc : 0.8833\n",
      "Epoch: 3701 train_loss : 0.4750 train_acc : 0.8065 val_loss : 0.2876 val_acc : 0.8833\n",
      "Epoch: 3801 train_loss : 0.4728 train_acc : 0.8068 val_loss : 0.2790 val_acc : 0.8843\n",
      "Epoch: 3901 train_loss : 0.4688 train_acc : 0.8062 val_loss : 0.2766 val_acc : 0.8837\n",
      "Epoch: 4001 train_loss : 0.4694 train_acc : 0.8085 val_loss : 0.2720 val_acc : 0.8853\n",
      "Epoch: 4101 train_loss : 0.4634 train_acc : 0.8101 val_loss : 0.2712 val_acc : 0.8853\n",
      "Epoch: 4201 train_loss : 0.4555 train_acc : 0.8112 val_loss : 0.2665 val_acc : 0.8883\n",
      "Epoch: 4301 train_loss : 0.4586 train_acc : 0.8121 val_loss : 0.2618 val_acc : 0.8900\n",
      "Epoch: 4401 train_loss : 0.4546 train_acc : 0.8143 val_loss : 0.2594 val_acc : 0.8913\n",
      "Epoch: 4501 train_loss : 0.4502 train_acc : 0.8157 val_loss : 0.2564 val_acc : 0.8920\n",
      "Epoch: 4601 train_loss : 0.4498 train_acc : 0.8168 val_loss : 0.2553 val_acc : 0.8930\n",
      "Epoch: 4701 train_loss : 0.4469 train_acc : 0.8173 val_loss : 0.2513 val_acc : 0.8950\n",
      "Epoch: 4801 train_loss : 0.4450 train_acc : 0.8179 val_loss : 0.2531 val_acc : 0.8940\n",
      "Epoch: 4901 train_loss : 0.4437 train_acc : 0.8196 val_loss : 0.2485 val_acc : 0.8960\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.85957295\n",
      "Execution time (seconds) was 115.256\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/7/\n",
      "[0.8253328  0.8293578  0.81104536]\n",
      "[0.04295172 0.9244077  0.03095046]\n",
      "Using activation combination 8 : sigmoid + elu\n",
      "Epoch: 0001 train_loss : 1.2527 train_acc : 0.3333 val_loss : 0.5390 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1041 train_acc : 0.4162 val_loss : 0.9134 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.0735 train_acc : 0.4201 val_loss : 0.9810 val_acc : 0.9853\n",
      "Epoch: 0301 train_loss : 1.0389 train_acc : 0.5238 val_loss : 0.9121 val_acc : 0.9867\n",
      "Epoch: 0401 train_loss : 0.9689 train_acc : 0.5874 val_loss : 0.8562 val_acc : 0.9083\n",
      "Epoch: 0501 train_loss : 0.8599 train_acc : 0.6361 val_loss : 0.7770 val_acc : 0.8047\n",
      "Epoch: 0601 train_loss : 0.7969 train_acc : 0.6764 val_loss : 0.6801 val_acc : 0.8023\n",
      "Epoch: 0701 train_loss : 0.7662 train_acc : 0.7020 val_loss : 0.6163 val_acc : 0.8243\n",
      "Epoch: 0801 train_loss : 0.7364 train_acc : 0.7178 val_loss : 0.5573 val_acc : 0.8390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0901 train_loss : 0.7104 train_acc : 0.7412 val_loss : 0.4993 val_acc : 0.8457\n",
      "Epoch: 1001 train_loss : 0.6845 train_acc : 0.7548 val_loss : 0.4437 val_acc : 0.8517\n",
      "Epoch: 1101 train_loss : 0.6588 train_acc : 0.7637 val_loss : 0.3966 val_acc : 0.8590\n",
      "Epoch: 1201 train_loss : 0.6383 train_acc : 0.7701 val_loss : 0.3576 val_acc : 0.8633\n",
      "Epoch: 1301 train_loss : 0.6205 train_acc : 0.7734 val_loss : 0.3329 val_acc : 0.8650\n",
      "Epoch: 1401 train_loss : 0.6024 train_acc : 0.7770 val_loss : 0.3107 val_acc : 0.8653\n",
      "Epoch: 1501 train_loss : 0.5881 train_acc : 0.7795 val_loss : 0.2904 val_acc : 0.8720\n",
      "Epoch: 1601 train_loss : 0.5800 train_acc : 0.7854 val_loss : 0.2812 val_acc : 0.8720\n",
      "Epoch: 1701 train_loss : 0.5731 train_acc : 0.7890 val_loss : 0.2667 val_acc : 0.8760\n",
      "Epoch: 1801 train_loss : 0.5599 train_acc : 0.7890 val_loss : 0.2556 val_acc : 0.8777\n",
      "Epoch: 1901 train_loss : 0.5555 train_acc : 0.7909 val_loss : 0.2499 val_acc : 0.8803\n",
      "Epoch: 2001 train_loss : 0.5451 train_acc : 0.7932 val_loss : 0.2369 val_acc : 0.8867\n",
      "Epoch: 2101 train_loss : 0.5461 train_acc : 0.7957 val_loss : 0.2338 val_acc : 0.8887\n",
      "Epoch: 2201 train_loss : 0.5362 train_acc : 0.7954 val_loss : 0.2228 val_acc : 0.8957\n",
      "Epoch: 2301 train_loss : 0.5273 train_acc : 0.7984 val_loss : 0.2224 val_acc : 0.8957\n",
      "Epoch: 2401 train_loss : 0.5218 train_acc : 0.7993 val_loss : 0.2211 val_acc : 0.8990\n",
      "Epoch: 2501 train_loss : 0.5200 train_acc : 0.8021 val_loss : 0.2108 val_acc : 0.9033\n",
      "Epoch: 2601 train_loss : 0.5154 train_acc : 0.8032 val_loss : 0.2122 val_acc : 0.9033\n",
      "Epoch: 2701 train_loss : 0.5107 train_acc : 0.8046 val_loss : 0.2067 val_acc : 0.9070\n",
      "Epoch: 2801 train_loss : 0.5094 train_acc : 0.8054 val_loss : 0.2057 val_acc : 0.9080\n",
      "Epoch: 2901 train_loss : 0.5047 train_acc : 0.8051 val_loss : 0.2033 val_acc : 0.9093\n",
      "Epoch: 3001 train_loss : 0.5042 train_acc : 0.8068 val_loss : 0.2068 val_acc : 0.9083\n",
      "Epoch: 3101 train_loss : 0.5000 train_acc : 0.8071 val_loss : 0.2047 val_acc : 0.9110\n",
      "Epoch: 3201 train_loss : 0.4967 train_acc : 0.8068 val_loss : 0.2006 val_acc : 0.9133\n",
      "Epoch: 3301 train_loss : 0.4904 train_acc : 0.8073 val_loss : 0.2023 val_acc : 0.9127\n",
      "Epoch: 3401 train_loss : 0.4913 train_acc : 0.8068 val_loss : 0.1978 val_acc : 0.9173\n",
      "Epoch: 3501 train_loss : 0.4841 train_acc : 0.8068 val_loss : 0.2006 val_acc : 0.9160\n",
      "Epoch: 3601 train_loss : 0.4839 train_acc : 0.8065 val_loss : 0.2028 val_acc : 0.9130\n",
      "Epoch: 3701 train_loss : 0.4786 train_acc : 0.8082 val_loss : 0.2028 val_acc : 0.9113\n",
      "Epoch: 3801 train_loss : 0.4774 train_acc : 0.8090 val_loss : 0.2045 val_acc : 0.9103\n",
      "Epoch: 3901 train_loss : 0.4725 train_acc : 0.8101 val_loss : 0.2077 val_acc : 0.9090\n",
      "Epoch: 4001 train_loss : 0.4728 train_acc : 0.8098 val_loss : 0.2027 val_acc : 0.9100\n",
      "Epoch: 4101 train_loss : 0.4686 train_acc : 0.8107 val_loss : 0.2072 val_acc : 0.9083\n",
      "Epoch: 4201 train_loss : 0.4701 train_acc : 0.8112 val_loss : 0.2089 val_acc : 0.9077\n",
      "Epoch: 4301 train_loss : 0.4663 train_acc : 0.8132 val_loss : 0.2067 val_acc : 0.9087\n",
      "Epoch: 4401 train_loss : 0.4635 train_acc : 0.8132 val_loss : 0.1993 val_acc : 0.9123\n",
      "Epoch: 4501 train_loss : 0.4641 train_acc : 0.8135 val_loss : 0.2032 val_acc : 0.9103\n",
      "Epoch: 4601 train_loss : 0.4577 train_acc : 0.8137 val_loss : 0.2075 val_acc : 0.9087\n",
      "Epoch: 4701 train_loss : 0.4580 train_acc : 0.8135 val_loss : 0.2104 val_acc : 0.9070\n",
      "Epoch: 4801 train_loss : 0.4589 train_acc : 0.8135 val_loss : 0.2105 val_acc : 0.9073\n",
      "Epoch: 4901 train_loss : 0.4578 train_acc : 0.8143 val_loss : 0.2104 val_acc : 0.9067\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.8577353\n",
      "Execution time (seconds) was 117.635\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/8/\n",
      "[0.8028731  0.83949504 0.80161943]\n",
      "[0.04178653 0.92342065 0.03417796]\n",
      "Using activation combination 9 : relu + tanh\n",
      "Epoch: 0001 train_loss : 1.2665 train_acc : 0.3333 val_loss : 0.5022 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0808 train_acc : 0.4220 val_loss : 1.0199 val_acc : 0.5140\n",
      "Epoch: 0201 train_loss : 0.9462 train_acc : 0.5304 val_loss : 0.9970 val_acc : 0.7173\n",
      "Epoch: 0301 train_loss : 0.8428 train_acc : 0.6214 val_loss : 0.9277 val_acc : 0.7847\n",
      "Epoch: 0401 train_loss : 0.7850 train_acc : 0.6764 val_loss : 0.8074 val_acc : 0.7993\n",
      "Epoch: 0501 train_loss : 0.7378 train_acc : 0.7023 val_loss : 0.6288 val_acc : 0.8253\n",
      "Epoch: 0601 train_loss : 0.6864 train_acc : 0.7431 val_loss : 0.4584 val_acc : 0.8333\n",
      "Epoch: 0701 train_loss : 0.6301 train_acc : 0.7698 val_loss : 0.3792 val_acc : 0.8403\n",
      "Epoch: 0801 train_loss : 0.5914 train_acc : 0.7887 val_loss : 0.3387 val_acc : 0.8480\n",
      "Epoch: 0901 train_loss : 0.5731 train_acc : 0.8007 val_loss : 0.3102 val_acc : 0.8510\n",
      "Epoch: 1001 train_loss : 0.5542 train_acc : 0.8032 val_loss : 0.3073 val_acc : 0.8490\n",
      "Epoch: 1101 train_loss : 0.5393 train_acc : 0.8085 val_loss : 0.3043 val_acc : 0.8497\n",
      "Epoch: 1201 train_loss : 0.5263 train_acc : 0.8115 val_loss : 0.2963 val_acc : 0.8507\n",
      "Epoch: 1301 train_loss : 0.5121 train_acc : 0.8140 val_loss : 0.2934 val_acc : 0.8490\n",
      "Epoch: 1401 train_loss : 0.5036 train_acc : 0.8151 val_loss : 0.2911 val_acc : 0.8480\n",
      "Epoch: 1501 train_loss : 0.4906 train_acc : 0.8146 val_loss : 0.2843 val_acc : 0.8490\n",
      "Epoch: 1601 train_loss : 0.4861 train_acc : 0.8173 val_loss : 0.2759 val_acc : 0.8487\n",
      "Epoch: 1701 train_loss : 0.4740 train_acc : 0.8185 val_loss : 0.2706 val_acc : 0.8490\n",
      "Epoch: 1801 train_loss : 0.4694 train_acc : 0.8201 val_loss : 0.2719 val_acc : 0.8487\n",
      "Epoch: 1901 train_loss : 0.4608 train_acc : 0.8207 val_loss : 0.2672 val_acc : 0.8520\n",
      "Epoch: 2001 train_loss : 0.4564 train_acc : 0.8221 val_loss : 0.2678 val_acc : 0.8527\n",
      "Epoch: 2101 train_loss : 0.4545 train_acc : 0.8260 val_loss : 0.2651 val_acc : 0.8540\n",
      "Epoch: 2201 train_loss : 0.4493 train_acc : 0.8249 val_loss : 0.2732 val_acc : 0.8523\n",
      "Epoch: 2301 train_loss : 0.4415 train_acc : 0.8262 val_loss : 0.2650 val_acc : 0.8560\n",
      "Epoch: 2401 train_loss : 0.4389 train_acc : 0.8268 val_loss : 0.2712 val_acc : 0.8547\n",
      "Epoch: 2501 train_loss : 0.4362 train_acc : 0.8287 val_loss : 0.2607 val_acc : 0.8590\n",
      "Epoch: 2601 train_loss : 0.4308 train_acc : 0.8296 val_loss : 0.2626 val_acc : 0.8593\n",
      "Epoch: 2701 train_loss : 0.4309 train_acc : 0.8301 val_loss : 0.2662 val_acc : 0.8593\n",
      "Epoch: 2801 train_loss : 0.4281 train_acc : 0.8285 val_loss : 0.2582 val_acc : 0.8640\n",
      "Epoch: 2901 train_loss : 0.4234 train_acc : 0.8299 val_loss : 0.2543 val_acc : 0.8643\n",
      "Epoch: 3001 train_loss : 0.4232 train_acc : 0.8304 val_loss : 0.2591 val_acc : 0.8647\n",
      "Epoch: 3101 train_loss : 0.4182 train_acc : 0.8310 val_loss : 0.2500 val_acc : 0.8677\n",
      "Epoch: 3201 train_loss : 0.4148 train_acc : 0.8329 val_loss : 0.2556 val_acc : 0.8663\n",
      "Epoch: 3301 train_loss : 0.4105 train_acc : 0.8340 val_loss : 0.2540 val_acc : 0.8673\n",
      "Epoch: 3401 train_loss : 0.4096 train_acc : 0.8346 val_loss : 0.2544 val_acc : 0.8670\n",
      "Epoch: 3501 train_loss : 0.4074 train_acc : 0.8346 val_loss : 0.2601 val_acc : 0.8657\n",
      "Epoch: 3601 train_loss : 0.4036 train_acc : 0.8343 val_loss : 0.2520 val_acc : 0.8690\n",
      "Epoch: 3701 train_loss : 0.4061 train_acc : 0.8363 val_loss : 0.2537 val_acc : 0.8687\n",
      "Epoch: 3801 train_loss : 0.4006 train_acc : 0.8374 val_loss : 0.2511 val_acc : 0.8703\n",
      "Epoch: 3901 train_loss : 0.4046 train_acc : 0.8388 val_loss : 0.2474 val_acc : 0.8723\n",
      "Epoch: 4001 train_loss : 0.3977 train_acc : 0.8385 val_loss : 0.2528 val_acc : 0.8717\n",
      "Epoch: 4101 train_loss : 0.3998 train_acc : 0.8393 val_loss : 0.2514 val_acc : 0.8737\n",
      "Epoch: 4201 train_loss : 0.3957 train_acc : 0.8413 val_loss : 0.2479 val_acc : 0.8753\n",
      "Epoch: 4301 train_loss : 0.3928 train_acc : 0.8413 val_loss : 0.2494 val_acc : 0.8747\n",
      "Epoch: 4401 train_loss : 0.3903 train_acc : 0.8424 val_loss : 0.2466 val_acc : 0.8757\n",
      "Epoch: 4501 train_loss : 0.3899 train_acc : 0.8429 val_loss : 0.2498 val_acc : 0.8747\n",
      "Epoch: 4601 train_loss : 0.3876 train_acc : 0.8432 val_loss : 0.2474 val_acc : 0.8760\n",
      "Epoch: 4701 train_loss : 0.3896 train_acc : 0.8446 val_loss : 0.2555 val_acc : 0.8733\n",
      "Epoch: 4801 train_loss : 0.3851 train_acc : 0.8451 val_loss : 0.2536 val_acc : 0.8753\n",
      "Epoch: 4901 train_loss : 0.3847 train_acc : 0.8454 val_loss : 0.2461 val_acc : 0.8770\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7874628\n",
      "Execution time (seconds) was 116.668\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/9/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84473993 0.86459286 0.83068135]\n",
      "[0.02767482 0.88101637 0.02905379]\n",
      "Using activation combination 10 : relu + sigmoid\n",
      "Epoch: 0001 train_loss : 1.1054 train_acc : 0.3333 val_loss : 0.9271 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 0.9749 train_acc : 0.5835 val_loss : 1.0389 val_acc : 0.3523\n",
      "Epoch: 0201 train_loss : 0.8205 train_acc : 0.6931 val_loss : 0.7093 val_acc : 0.8053\n",
      "Epoch: 0301 train_loss : 0.7159 train_acc : 0.7470 val_loss : 0.5091 val_acc : 0.8337\n",
      "Epoch: 0401 train_loss : 0.6478 train_acc : 0.7729 val_loss : 0.4588 val_acc : 0.8197\n",
      "Epoch: 0501 train_loss : 0.6104 train_acc : 0.7848 val_loss : 0.4275 val_acc : 0.8290\n",
      "Epoch: 0601 train_loss : 0.5847 train_acc : 0.7940 val_loss : 0.3949 val_acc : 0.8493\n",
      "Epoch: 0701 train_loss : 0.5635 train_acc : 0.8009 val_loss : 0.3633 val_acc : 0.8670\n",
      "Epoch: 0801 train_loss : 0.5474 train_acc : 0.8046 val_loss : 0.3488 val_acc : 0.8750\n",
      "Epoch: 0901 train_loss : 0.5347 train_acc : 0.8043 val_loss : 0.3214 val_acc : 0.8857\n",
      "Epoch: 1001 train_loss : 0.5227 train_acc : 0.8101 val_loss : 0.3139 val_acc : 0.8793\n",
      "Epoch: 1101 train_loss : 0.5162 train_acc : 0.8126 val_loss : 0.3070 val_acc : 0.8747\n",
      "Epoch: 1201 train_loss : 0.5071 train_acc : 0.8126 val_loss : 0.3006 val_acc : 0.8750\n",
      "Epoch: 1301 train_loss : 0.4990 train_acc : 0.8137 val_loss : 0.2966 val_acc : 0.8730\n",
      "Epoch: 1401 train_loss : 0.4911 train_acc : 0.8173 val_loss : 0.2971 val_acc : 0.8710\n",
      "Epoch: 1501 train_loss : 0.4881 train_acc : 0.8204 val_loss : 0.2986 val_acc : 0.8703\n",
      "Epoch: 1601 train_loss : 0.4817 train_acc : 0.8212 val_loss : 0.3015 val_acc : 0.8683\n",
      "Epoch: 1701 train_loss : 0.4711 train_acc : 0.8218 val_loss : 0.3033 val_acc : 0.8677\n",
      "Epoch: 1801 train_loss : 0.4712 train_acc : 0.8235 val_loss : 0.3005 val_acc : 0.8690\n",
      "Epoch: 1901 train_loss : 0.4660 train_acc : 0.8229 val_loss : 0.3056 val_acc : 0.8683\n",
      "Epoch: 2001 train_loss : 0.4609 train_acc : 0.8226 val_loss : 0.3108 val_acc : 0.8673\n",
      "Epoch: 2101 train_loss : 0.4565 train_acc : 0.8232 val_loss : 0.3094 val_acc : 0.8670\n",
      "Epoch: 2201 train_loss : 0.4531 train_acc : 0.8251 val_loss : 0.3092 val_acc : 0.8670\n",
      "Epoch: 2301 train_loss : 0.4461 train_acc : 0.8260 val_loss : 0.3084 val_acc : 0.8673\n",
      "Epoch: 2401 train_loss : 0.4414 train_acc : 0.8262 val_loss : 0.3168 val_acc : 0.8643\n",
      "Epoch: 2501 train_loss : 0.4396 train_acc : 0.8274 val_loss : 0.3095 val_acc : 0.8663\n",
      "Epoch: 2601 train_loss : 0.4333 train_acc : 0.8290 val_loss : 0.3056 val_acc : 0.8680\n",
      "Epoch: 2701 train_loss : 0.4355 train_acc : 0.8296 val_loss : 0.3059 val_acc : 0.8683\n",
      "Epoch: 2801 train_loss : 0.4284 train_acc : 0.8304 val_loss : 0.3037 val_acc : 0.8697\n",
      "Epoch: 2901 train_loss : 0.4248 train_acc : 0.8301 val_loss : 0.3029 val_acc : 0.8700\n",
      "Epoch: 3001 train_loss : 0.4231 train_acc : 0.8301 val_loss : 0.3011 val_acc : 0.8703\n",
      "Epoch: 3101 train_loss : 0.4221 train_acc : 0.8301 val_loss : 0.3017 val_acc : 0.8703\n",
      "Epoch: 3201 train_loss : 0.4166 train_acc : 0.8326 val_loss : 0.2950 val_acc : 0.8717\n",
      "Epoch: 3301 train_loss : 0.4171 train_acc : 0.8349 val_loss : 0.2907 val_acc : 0.8720\n",
      "Epoch: 3401 train_loss : 0.4138 train_acc : 0.8351 val_loss : 0.2914 val_acc : 0.8713\n",
      "Epoch: 3501 train_loss : 0.4106 train_acc : 0.8349 val_loss : 0.2897 val_acc : 0.8727\n",
      "Epoch: 3601 train_loss : 0.4104 train_acc : 0.8357 val_loss : 0.2882 val_acc : 0.8733\n",
      "Epoch: 3701 train_loss : 0.4109 train_acc : 0.8374 val_loss : 0.2845 val_acc : 0.8757\n",
      "Epoch: 3801 train_loss : 0.4037 train_acc : 0.8374 val_loss : 0.2891 val_acc : 0.8740\n",
      "Epoch: 3901 train_loss : 0.4014 train_acc : 0.8385 val_loss : 0.2766 val_acc : 0.8783\n",
      "Epoch: 4001 train_loss : 0.4053 train_acc : 0.8393 val_loss : 0.2845 val_acc : 0.8750\n",
      "Epoch: 4101 train_loss : 0.4016 train_acc : 0.8401 val_loss : 0.2855 val_acc : 0.8743\n",
      "Epoch: 4201 train_loss : 0.3989 train_acc : 0.8413 val_loss : 0.2814 val_acc : 0.8753\n",
      "Epoch: 4301 train_loss : 0.3967 train_acc : 0.8421 val_loss : 0.2829 val_acc : 0.8753\n",
      "Epoch: 4401 train_loss : 0.3916 train_acc : 0.8426 val_loss : 0.2745 val_acc : 0.8787\n",
      "Epoch: 4501 train_loss : 0.3949 train_acc : 0.8432 val_loss : 0.2783 val_acc : 0.8757\n",
      "Epoch: 4601 train_loss : 0.3919 train_acc : 0.8440 val_loss : 0.2735 val_acc : 0.8773\n",
      "Epoch: 4701 train_loss : 0.3910 train_acc : 0.8438 val_loss : 0.2792 val_acc : 0.8743\n",
      "Epoch: 4801 train_loss : 0.3910 train_acc : 0.8443 val_loss : 0.2803 val_acc : 0.8737\n",
      "Epoch: 4901 train_loss : 0.3898 train_acc : 0.8454 val_loss : 0.2718 val_acc : 0.8753\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7709928\n",
      "Execution time (seconds) was 115.918\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/10/\n",
      "[0.84429066 0.86319668 0.82989265]\n",
      "[0.03375708 0.87046632 0.02440188]\n",
      "Using activation combination 11 : relu + relu\n",
      "Epoch: 0001 train_loss : 1.2818 train_acc : 0.3333 val_loss : 0.4858 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1645 train_acc : 0.3344 val_loss : 0.6515 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.0148 train_acc : 0.5485 val_loss : 0.6766 val_acc : 0.8557\n",
      "Epoch: 0301 train_loss : 0.9722 train_acc : 0.5677 val_loss : 0.7262 val_acc : 0.8313\n",
      "Epoch: 0401 train_loss : 0.9459 train_acc : 0.5716 val_loss : 0.7416 val_acc : 0.8263\n",
      "Epoch: 0501 train_loss : 0.9242 train_acc : 0.5710 val_loss : 0.7614 val_acc : 0.8240\n",
      "Epoch: 0601 train_loss : 0.9103 train_acc : 0.5735 val_loss : 0.7709 val_acc : 0.8280\n",
      "Epoch: 0701 train_loss : 0.8939 train_acc : 0.5749 val_loss : 0.7802 val_acc : 0.8363\n",
      "Epoch: 0801 train_loss : 0.8788 train_acc : 0.5777 val_loss : 0.8096 val_acc : 0.8323\n",
      "Epoch: 0901 train_loss : 0.8634 train_acc : 0.5791 val_loss : 0.8139 val_acc : 0.8433\n",
      "Epoch: 1001 train_loss : 0.8496 train_acc : 0.5810 val_loss : 0.8273 val_acc : 0.8477\n",
      "Epoch: 1101 train_loss : 0.8391 train_acc : 0.5822 val_loss : 0.8451 val_acc : 0.8500\n",
      "Epoch: 1201 train_loss : 0.8266 train_acc : 0.5833 val_loss : 0.8580 val_acc : 0.8523\n",
      "Epoch: 1301 train_loss : 0.8137 train_acc : 0.5830 val_loss : 0.8671 val_acc : 0.8557\n",
      "Epoch: 1401 train_loss : 0.8053 train_acc : 0.5852 val_loss : 0.8769 val_acc : 0.8547\n",
      "Epoch: 1501 train_loss : 0.7966 train_acc : 0.5888 val_loss : 0.8774 val_acc : 0.8527\n",
      "Epoch: 1601 train_loss : 0.7846 train_acc : 0.5916 val_loss : 0.8942 val_acc : 0.8403\n",
      "Epoch: 1701 train_loss : 0.7807 train_acc : 0.5961 val_loss : 0.8964 val_acc : 0.8400\n",
      "Epoch: 1801 train_loss : 0.7721 train_acc : 0.5994 val_loss : 0.9089 val_acc : 0.8377\n",
      "Epoch: 1901 train_loss : 0.7656 train_acc : 0.6005 val_loss : 0.9106 val_acc : 0.8373\n",
      "Epoch: 2001 train_loss : 0.7592 train_acc : 0.6030 val_loss : 0.9127 val_acc : 0.8367\n",
      "Epoch: 2101 train_loss : 0.7525 train_acc : 0.6052 val_loss : 0.9073 val_acc : 0.8377\n",
      "Epoch: 2201 train_loss : 0.7442 train_acc : 0.6119 val_loss : 0.9090 val_acc : 0.8370\n",
      "Epoch: 2301 train_loss : 0.7445 train_acc : 0.6155 val_loss : 0.9110 val_acc : 0.8357\n",
      "Epoch: 2401 train_loss : 0.7354 train_acc : 0.6169 val_loss : 0.9125 val_acc : 0.8347\n",
      "Epoch: 2501 train_loss : 0.7328 train_acc : 0.6230 val_loss : 0.9149 val_acc : 0.8333\n",
      "Epoch: 2601 train_loss : 0.7274 train_acc : 0.6264 val_loss : 0.9186 val_acc : 0.8313\n",
      "Epoch: 2701 train_loss : 0.7208 train_acc : 0.6347 val_loss : 0.9196 val_acc : 0.8303\n",
      "Epoch: 2801 train_loss : 0.7153 train_acc : 0.6380 val_loss : 0.9223 val_acc : 0.8297\n",
      "Epoch: 2901 train_loss : 0.7145 train_acc : 0.6389 val_loss : 0.9189 val_acc : 0.8303\n",
      "Epoch: 3001 train_loss : 0.7096 train_acc : 0.6403 val_loss : 0.9150 val_acc : 0.8303\n",
      "Epoch: 3101 train_loss : 0.7057 train_acc : 0.6436 val_loss : 0.9144 val_acc : 0.8310\n",
      "Epoch: 3201 train_loss : 0.6988 train_acc : 0.6478 val_loss : 0.9184 val_acc : 0.8307\n",
      "Epoch: 3301 train_loss : 0.6985 train_acc : 0.6489 val_loss : 0.9188 val_acc : 0.8327\n",
      "Epoch: 3401 train_loss : 0.6957 train_acc : 0.6494 val_loss : 0.9103 val_acc : 0.8337\n",
      "Epoch: 3501 train_loss : 0.6891 train_acc : 0.6517 val_loss : 0.9132 val_acc : 0.8337\n",
      "Epoch: 3601 train_loss : 0.6875 train_acc : 0.6533 val_loss : 0.9106 val_acc : 0.8313\n",
      "Epoch: 3701 train_loss : 0.6881 train_acc : 0.6561 val_loss : 0.9141 val_acc : 0.8313\n",
      "Epoch: 3801 train_loss : 0.6837 train_acc : 0.6606 val_loss : 0.9090 val_acc : 0.8313\n",
      "Epoch: 3901 train_loss : 0.6780 train_acc : 0.6614 val_loss : 0.9038 val_acc : 0.8317\n",
      "Epoch: 4001 train_loss : 0.6769 train_acc : 0.6614 val_loss : 0.9063 val_acc : 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4101 train_loss : 0.6725 train_acc : 0.6636 val_loss : 0.9066 val_acc : 0.8320\n",
      "Epoch: 4201 train_loss : 0.6720 train_acc : 0.6631 val_loss : 0.9032 val_acc : 0.8360\n",
      "Epoch: 4301 train_loss : 0.6703 train_acc : 0.6675 val_loss : 0.9025 val_acc : 0.8377\n",
      "Epoch: 4401 train_loss : 0.6667 train_acc : 0.6633 val_loss : 0.8929 val_acc : 0.8423\n",
      "Epoch: 4501 train_loss : 0.6678 train_acc : 0.6686 val_loss : 0.8840 val_acc : 0.8450\n",
      "Epoch: 4601 train_loss : 0.6640 train_acc : 0.6717 val_loss : 0.8993 val_acc : 0.8433\n",
      "Epoch: 4701 train_loss : 0.6630 train_acc : 0.6731 val_loss : 0.8854 val_acc : 0.8457\n",
      "Epoch: 4801 train_loss : 0.6621 train_acc : 0.6750 val_loss : 0.8880 val_acc : 0.8457\n",
      "Epoch: 4901 train_loss : 0.6604 train_acc : 0.6772 val_loss : 0.8971 val_acc : 0.8450\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.804886\n",
      "Execution time (seconds) was 118.703\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/11/\n",
      "[0.86520875 0.67257893 0.42795699]\n",
      "[0.0256917  0.89201478 0.00781577]\n",
      "Using activation combination 12 : relu + elu\n",
      "Epoch: 0001 train_loss : 1.2848 train_acc : 0.3333 val_loss : 0.4896 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1830 train_acc : 0.3333 val_loss : 0.6441 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.1130 train_acc : 0.3333 val_loss : 0.9216 val_acc : 0.9970\n",
      "Epoch: 0301 train_loss : 1.1001 train_acc : 0.3336 val_loss : 1.0857 val_acc : 0.0027\n",
      "Epoch: 0401 train_loss : 1.0987 train_acc : 0.3336 val_loss : 1.1000 val_acc : 0.0030\n",
      "Epoch: 0501 train_loss : 1.0986 train_acc : 0.3339 val_loss : 1.0990 val_acc : 0.0047\n",
      "Epoch: 0601 train_loss : 1.0986 train_acc : 0.3333 val_loss : 1.0972 val_acc : 0.9970\n",
      "Epoch: 0701 train_loss : 1.0130 train_acc : 0.4748 val_loss : 0.6303 val_acc : 0.9727\n",
      "Epoch: 0801 train_loss : 0.8830 train_acc : 0.5958 val_loss : 0.9216 val_acc : 0.3213\n",
      "Epoch: 0901 train_loss : 0.8285 train_acc : 0.6364 val_loss : 0.9478 val_acc : 0.5040\n",
      "Epoch: 1001 train_loss : 0.8043 train_acc : 0.6569 val_loss : 0.9097 val_acc : 0.6203\n",
      "Epoch: 1101 train_loss : 0.7907 train_acc : 0.6683 val_loss : 0.8735 val_acc : 0.6967\n",
      "Epoch: 1201 train_loss : 0.7796 train_acc : 0.6717 val_loss : 0.8371 val_acc : 0.7383\n",
      "Epoch: 1301 train_loss : 0.7718 train_acc : 0.6806 val_loss : 0.8023 val_acc : 0.7703\n",
      "Epoch: 1401 train_loss : 0.7640 train_acc : 0.6847 val_loss : 0.7726 val_acc : 0.7957\n",
      "Epoch: 1501 train_loss : 0.7547 train_acc : 0.6878 val_loss : 0.7447 val_acc : 0.8107\n",
      "Epoch: 1601 train_loss : 0.7541 train_acc : 0.6897 val_loss : 0.7228 val_acc : 0.8177\n",
      "Epoch: 1701 train_loss : 0.7453 train_acc : 0.6956 val_loss : 0.7032 val_acc : 0.8240\n",
      "Epoch: 1801 train_loss : 0.7401 train_acc : 0.6964 val_loss : 0.6880 val_acc : 0.8327\n",
      "Epoch: 1901 train_loss : 0.7357 train_acc : 0.6995 val_loss : 0.6814 val_acc : 0.8400\n",
      "Epoch: 2001 train_loss : 0.7287 train_acc : 0.7031 val_loss : 0.6705 val_acc : 0.8557\n",
      "Epoch: 2101 train_loss : 0.7186 train_acc : 0.7020 val_loss : 0.6573 val_acc : 0.8590\n",
      "Epoch: 2201 train_loss : 0.7119 train_acc : 0.7064 val_loss : 0.6253 val_acc : 0.8753\n",
      "Epoch: 2301 train_loss : 0.6968 train_acc : 0.7137 val_loss : 0.5453 val_acc : 0.8960\n",
      "Epoch: 2401 train_loss : 0.6365 train_acc : 0.7467 val_loss : 0.4139 val_acc : 0.9067\n",
      "Epoch: 2501 train_loss : 0.5902 train_acc : 0.7590 val_loss : 0.3516 val_acc : 0.8937\n",
      "Epoch: 2601 train_loss : 0.5471 train_acc : 0.7765 val_loss : 0.3191 val_acc : 0.8890\n",
      "Epoch: 2701 train_loss : 0.5259 train_acc : 0.7882 val_loss : 0.2979 val_acc : 0.8790\n",
      "Epoch: 2801 train_loss : 0.5166 train_acc : 0.7957 val_loss : 0.2852 val_acc : 0.8743\n",
      "Epoch: 2901 train_loss : 0.5070 train_acc : 0.8009 val_loss : 0.2834 val_acc : 0.8733\n",
      "Epoch: 3001 train_loss : 0.4955 train_acc : 0.8029 val_loss : 0.2738 val_acc : 0.8753\n",
      "Epoch: 3101 train_loss : 0.4937 train_acc : 0.8040 val_loss : 0.2721 val_acc : 0.8760\n",
      "Epoch: 3201 train_loss : 0.4912 train_acc : 0.8043 val_loss : 0.2635 val_acc : 0.8763\n",
      "Epoch: 3301 train_loss : 0.4826 train_acc : 0.8054 val_loss : 0.2521 val_acc : 0.8793\n",
      "Epoch: 3401 train_loss : 0.4806 train_acc : 0.8065 val_loss : 0.2475 val_acc : 0.8797\n",
      "Epoch: 3501 train_loss : 0.4771 train_acc : 0.8090 val_loss : 0.2431 val_acc : 0.8803\n",
      "Epoch: 3601 train_loss : 0.4747 train_acc : 0.8104 val_loss : 0.2368 val_acc : 0.8820\n",
      "Epoch: 3701 train_loss : 0.4716 train_acc : 0.8126 val_loss : 0.2258 val_acc : 0.8847\n",
      "Epoch: 3801 train_loss : 0.4679 train_acc : 0.8157 val_loss : 0.2247 val_acc : 0.8853\n",
      "Epoch: 3901 train_loss : 0.4624 train_acc : 0.8162 val_loss : 0.2239 val_acc : 0.8857\n",
      "Epoch: 4001 train_loss : 0.4598 train_acc : 0.8185 val_loss : 0.2199 val_acc : 0.8887\n",
      "Epoch: 4101 train_loss : 0.4560 train_acc : 0.8201 val_loss : 0.2247 val_acc : 0.8890\n",
      "Epoch: 4201 train_loss : 0.4540 train_acc : 0.8221 val_loss : 0.2238 val_acc : 0.8893\n",
      "Epoch: 4301 train_loss : 0.4552 train_acc : 0.8240 val_loss : 0.2219 val_acc : 0.8897\n",
      "Epoch: 4401 train_loss : 0.4471 train_acc : 0.8251 val_loss : 0.2242 val_acc : 0.8900\n",
      "Epoch: 4501 train_loss : 0.4466 train_acc : 0.8265 val_loss : 0.2211 val_acc : 0.8913\n",
      "Epoch: 4601 train_loss : 0.4412 train_acc : 0.8271 val_loss : 0.2235 val_acc : 0.8913\n",
      "Epoch: 4701 train_loss : 0.4410 train_acc : 0.8285 val_loss : 0.2203 val_acc : 0.8927\n",
      "Epoch: 4801 train_loss : 0.4380 train_acc : 0.8296 val_loss : 0.2223 val_acc : 0.8940\n",
      "Epoch: 4901 train_loss : 0.4335 train_acc : 0.8293 val_loss : 0.2240 val_acc : 0.8967\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.8545219\n",
      "Execution time (seconds) was 120.276\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/12/\n",
      "[0.82736925 0.8489342  0.81829122]\n",
      "[0.03481915 0.9215333  0.03199079]\n",
      "Using activation combination 13 : elu + tanh\n",
      "Epoch: 0001 train_loss : 1.3181 train_acc : 0.3333 val_loss : 0.4163 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1098 train_acc : 0.3333 val_loss : 0.7529 val_acc : 0.9970\n",
      "Epoch: 0201 train_loss : 1.0002 train_acc : 0.4879 val_loss : 0.7753 val_acc : 0.9053\n",
      "Epoch: 0301 train_loss : 0.8963 train_acc : 0.5505 val_loss : 0.7118 val_acc : 0.8360\n",
      "Epoch: 0401 train_loss : 0.8154 train_acc : 0.6611 val_loss : 0.6309 val_acc : 0.8527\n",
      "Epoch: 0501 train_loss : 0.7439 train_acc : 0.7131 val_loss : 0.4639 val_acc : 0.8850\n",
      "Epoch: 0601 train_loss : 0.6617 train_acc : 0.7509 val_loss : 0.3326 val_acc : 0.8893\n",
      "Epoch: 0701 train_loss : 0.5972 train_acc : 0.7820 val_loss : 0.2809 val_acc : 0.8873\n",
      "Epoch: 0801 train_loss : 0.5600 train_acc : 0.7915 val_loss : 0.2588 val_acc : 0.8920\n",
      "Epoch: 0901 train_loss : 0.5357 train_acc : 0.7982 val_loss : 0.2345 val_acc : 0.8957\n",
      "Epoch: 1001 train_loss : 0.5214 train_acc : 0.8040 val_loss : 0.2224 val_acc : 0.8950\n",
      "Epoch: 1101 train_loss : 0.5069 train_acc : 0.8062 val_loss : 0.2196 val_acc : 0.8937\n",
      "Epoch: 1201 train_loss : 0.5028 train_acc : 0.8082 val_loss : 0.2150 val_acc : 0.8993\n",
      "Epoch: 1301 train_loss : 0.4933 train_acc : 0.8112 val_loss : 0.2165 val_acc : 0.8973\n",
      "Epoch: 1401 train_loss : 0.4846 train_acc : 0.8137 val_loss : 0.2189 val_acc : 0.8963\n",
      "Epoch: 1501 train_loss : 0.4809 train_acc : 0.8140 val_loss : 0.2166 val_acc : 0.8963\n",
      "Epoch: 1601 train_loss : 0.4777 train_acc : 0.8132 val_loss : 0.2224 val_acc : 0.8940\n",
      "Epoch: 1701 train_loss : 0.4735 train_acc : 0.8135 val_loss : 0.2241 val_acc : 0.8940\n",
      "Epoch: 1801 train_loss : 0.4662 train_acc : 0.8151 val_loss : 0.2266 val_acc : 0.8937\n",
      "Epoch: 1901 train_loss : 0.4610 train_acc : 0.8171 val_loss : 0.2294 val_acc : 0.8980\n",
      "Epoch: 2001 train_loss : 0.4575 train_acc : 0.8176 val_loss : 0.2304 val_acc : 0.8993\n",
      "Epoch: 2101 train_loss : 0.4564 train_acc : 0.8190 val_loss : 0.2272 val_acc : 0.9033\n",
      "Epoch: 2201 train_loss : 0.4537 train_acc : 0.8207 val_loss : 0.2268 val_acc : 0.9070\n",
      "Epoch: 2301 train_loss : 0.4516 train_acc : 0.8221 val_loss : 0.2261 val_acc : 0.9103\n",
      "Epoch: 2401 train_loss : 0.4481 train_acc : 0.8235 val_loss : 0.2266 val_acc : 0.9107\n",
      "Epoch: 2501 train_loss : 0.4434 train_acc : 0.8232 val_loss : 0.2224 val_acc : 0.9117\n",
      "Epoch: 2601 train_loss : 0.4445 train_acc : 0.8229 val_loss : 0.2202 val_acc : 0.9130\n",
      "Epoch: 2701 train_loss : 0.4408 train_acc : 0.8229 val_loss : 0.2205 val_acc : 0.9130\n",
      "Epoch: 2801 train_loss : 0.4390 train_acc : 0.8240 val_loss : 0.2203 val_acc : 0.9137\n",
      "Epoch: 2901 train_loss : 0.4366 train_acc : 0.8249 val_loss : 0.2199 val_acc : 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3001 train_loss : 0.4336 train_acc : 0.8276 val_loss : 0.2185 val_acc : 0.9147\n",
      "Epoch: 3101 train_loss : 0.4322 train_acc : 0.8274 val_loss : 0.2224 val_acc : 0.9140\n",
      "Epoch: 3201 train_loss : 0.4302 train_acc : 0.8276 val_loss : 0.2153 val_acc : 0.9157\n",
      "Epoch: 3301 train_loss : 0.4245 train_acc : 0.8287 val_loss : 0.2216 val_acc : 0.9143\n",
      "Epoch: 3401 train_loss : 0.4257 train_acc : 0.8299 val_loss : 0.2193 val_acc : 0.9157\n",
      "Epoch: 3501 train_loss : 0.4233 train_acc : 0.8307 val_loss : 0.2203 val_acc : 0.9150\n",
      "Epoch: 3601 train_loss : 0.4170 train_acc : 0.8324 val_loss : 0.2223 val_acc : 0.9147\n",
      "Epoch: 3701 train_loss : 0.4176 train_acc : 0.8321 val_loss : 0.2230 val_acc : 0.9150\n",
      "Epoch: 3801 train_loss : 0.4155 train_acc : 0.8332 val_loss : 0.2257 val_acc : 0.9140\n",
      "Epoch: 3901 train_loss : 0.4117 train_acc : 0.8338 val_loss : 0.2298 val_acc : 0.9100\n",
      "Epoch: 4001 train_loss : 0.4098 train_acc : 0.8346 val_loss : 0.2312 val_acc : 0.9060\n",
      "Epoch: 4101 train_loss : 0.4106 train_acc : 0.8343 val_loss : 0.2332 val_acc : 0.8953\n",
      "Epoch: 4201 train_loss : 0.4074 train_acc : 0.8346 val_loss : 0.2323 val_acc : 0.8937\n",
      "Epoch: 4301 train_loss : 0.4069 train_acc : 0.8351 val_loss : 0.2353 val_acc : 0.8927\n",
      "Epoch: 4401 train_loss : 0.4018 train_acc : 0.8357 val_loss : 0.2383 val_acc : 0.8917\n",
      "Epoch: 4501 train_loss : 0.4015 train_acc : 0.8363 val_loss : 0.2409 val_acc : 0.8910\n",
      "Epoch: 4601 train_loss : 0.3998 train_acc : 0.8379 val_loss : 0.2442 val_acc : 0.8880\n",
      "Epoch: 4701 train_loss : 0.4013 train_acc : 0.8382 val_loss : 0.2405 val_acc : 0.8887\n",
      "Epoch: 4801 train_loss : 0.3952 train_acc : 0.8390 val_loss : 0.2465 val_acc : 0.8860\n",
      "Epoch: 4901 train_loss : 0.3974 train_acc : 0.8396 val_loss : 0.2474 val_acc : 0.8853\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7946364\n",
      "Execution time (seconds) was 125.432\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/13/\n",
      "[0.83379611 0.86712644 0.82305845]\n",
      "[0.02469537 0.88553528 0.03134457]\n",
      "Using activation combination 14 : elu + sigmoid\n",
      "Epoch: 0001 train_loss : 1.1318 train_acc : 0.3336 val_loss : 0.9101 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0736 train_acc : 0.4448 val_loss : 0.9597 val_acc : 0.9790\n",
      "Epoch: 0201 train_loss : 0.9133 train_acc : 0.6550 val_loss : 0.7428 val_acc : 0.9030\n",
      "Epoch: 0301 train_loss : 0.7945 train_acc : 0.6984 val_loss : 0.5437 val_acc : 0.8547\n",
      "Epoch: 0401 train_loss : 0.7019 train_acc : 0.7495 val_loss : 0.4696 val_acc : 0.8343\n",
      "Epoch: 0501 train_loss : 0.6465 train_acc : 0.7759 val_loss : 0.4273 val_acc : 0.8417\n",
      "Epoch: 0601 train_loss : 0.6108 train_acc : 0.7898 val_loss : 0.3907 val_acc : 0.8487\n",
      "Epoch: 0701 train_loss : 0.5905 train_acc : 0.8012 val_loss : 0.3670 val_acc : 0.8547\n",
      "Epoch: 0801 train_loss : 0.5721 train_acc : 0.8046 val_loss : 0.3521 val_acc : 0.8587\n",
      "Epoch: 0901 train_loss : 0.5610 train_acc : 0.8059 val_loss : 0.3454 val_acc : 0.8657\n",
      "Epoch: 1001 train_loss : 0.5504 train_acc : 0.8085 val_loss : 0.3399 val_acc : 0.8680\n",
      "Epoch: 1101 train_loss : 0.5381 train_acc : 0.8093 val_loss : 0.3381 val_acc : 0.8673\n",
      "Epoch: 1201 train_loss : 0.5315 train_acc : 0.8093 val_loss : 0.3276 val_acc : 0.8707\n",
      "Epoch: 1301 train_loss : 0.5236 train_acc : 0.8101 val_loss : 0.3264 val_acc : 0.8693\n",
      "Epoch: 1401 train_loss : 0.5176 train_acc : 0.8115 val_loss : 0.3227 val_acc : 0.8697\n",
      "Epoch: 1501 train_loss : 0.5126 train_acc : 0.8137 val_loss : 0.3175 val_acc : 0.8703\n",
      "Epoch: 1601 train_loss : 0.5080 train_acc : 0.8140 val_loss : 0.3125 val_acc : 0.8713\n",
      "Epoch: 1701 train_loss : 0.5009 train_acc : 0.8140 val_loss : 0.3116 val_acc : 0.8710\n",
      "Epoch: 1801 train_loss : 0.4972 train_acc : 0.8151 val_loss : 0.3063 val_acc : 0.8713\n",
      "Epoch: 1901 train_loss : 0.4936 train_acc : 0.8160 val_loss : 0.3091 val_acc : 0.8687\n",
      "Epoch: 2001 train_loss : 0.4920 train_acc : 0.8173 val_loss : 0.3036 val_acc : 0.8700\n",
      "Epoch: 2101 train_loss : 0.4888 train_acc : 0.8185 val_loss : 0.3017 val_acc : 0.8707\n",
      "Epoch: 2201 train_loss : 0.4812 train_acc : 0.8204 val_loss : 0.2979 val_acc : 0.8730\n",
      "Epoch: 2301 train_loss : 0.4800 train_acc : 0.8229 val_loss : 0.2969 val_acc : 0.8730\n",
      "Epoch: 2401 train_loss : 0.4796 train_acc : 0.8235 val_loss : 0.3031 val_acc : 0.8703\n",
      "Epoch: 2501 train_loss : 0.4708 train_acc : 0.8246 val_loss : 0.2942 val_acc : 0.8740\n",
      "Epoch: 2601 train_loss : 0.4648 train_acc : 0.8240 val_loss : 0.2962 val_acc : 0.8723\n",
      "Epoch: 2701 train_loss : 0.4673 train_acc : 0.8265 val_loss : 0.2934 val_acc : 0.8733\n",
      "Epoch: 2801 train_loss : 0.4637 train_acc : 0.8268 val_loss : 0.2856 val_acc : 0.8750\n",
      "Epoch: 2901 train_loss : 0.4633 train_acc : 0.8287 val_loss : 0.2833 val_acc : 0.8753\n",
      "Epoch: 3001 train_loss : 0.4588 train_acc : 0.8301 val_loss : 0.2842 val_acc : 0.8747\n",
      "Epoch: 3101 train_loss : 0.4608 train_acc : 0.8326 val_loss : 0.2771 val_acc : 0.8750\n",
      "Epoch: 3201 train_loss : 0.4565 train_acc : 0.8335 val_loss : 0.2763 val_acc : 0.8750\n",
      "Epoch: 3301 train_loss : 0.4557 train_acc : 0.8349 val_loss : 0.2802 val_acc : 0.8753\n",
      "Epoch: 3401 train_loss : 0.4522 train_acc : 0.8360 val_loss : 0.2740 val_acc : 0.8757\n",
      "Epoch: 3501 train_loss : 0.4513 train_acc : 0.8379 val_loss : 0.2773 val_acc : 0.8743\n",
      "Epoch: 3601 train_loss : 0.4481 train_acc : 0.8379 val_loss : 0.2698 val_acc : 0.8787\n",
      "Epoch: 3701 train_loss : 0.4412 train_acc : 0.8385 val_loss : 0.2754 val_acc : 0.8767\n",
      "Epoch: 3801 train_loss : 0.4380 train_acc : 0.8388 val_loss : 0.2701 val_acc : 0.8790\n",
      "Epoch: 3901 train_loss : 0.4397 train_acc : 0.8399 val_loss : 0.2707 val_acc : 0.8783\n",
      "Epoch: 4001 train_loss : 0.4361 train_acc : 0.8410 val_loss : 0.2710 val_acc : 0.8780\n",
      "Epoch: 4101 train_loss : 0.4347 train_acc : 0.8421 val_loss : 0.2758 val_acc : 0.8763\n",
      "Epoch: 4201 train_loss : 0.4349 train_acc : 0.8418 val_loss : 0.2744 val_acc : 0.8763\n",
      "Epoch: 4301 train_loss : 0.4342 train_acc : 0.8418 val_loss : 0.2798 val_acc : 0.8750\n",
      "Epoch: 4401 train_loss : 0.4295 train_acc : 0.8440 val_loss : 0.2757 val_acc : 0.8760\n",
      "Epoch: 4501 train_loss : 0.4283 train_acc : 0.8446 val_loss : 0.2802 val_acc : 0.8747\n",
      "Epoch: 4601 train_loss : 0.4296 train_acc : 0.8460 val_loss : 0.2800 val_acc : 0.8747\n",
      "Epoch: 4701 train_loss : 0.4260 train_acc : 0.8465 val_loss : 0.2818 val_acc : 0.8743\n",
      "Epoch: 4801 train_loss : 0.4201 train_acc : 0.8463 val_loss : 0.2831 val_acc : 0.8743\n",
      "Epoch: 4901 train_loss : 0.4205 train_acc : 0.8474 val_loss : 0.2894 val_acc : 0.8740\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.7811932\n",
      "Execution time (seconds) was 123.969\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/14/\n",
      "[0.8433642  0.86843329 0.83068135]\n",
      "[0.02426737 0.87712381 0.02980693]\n",
      "Using activation combination 15 : elu + relu\n",
      "Epoch: 0001 train_loss : 1.2455 train_acc : 0.3333 val_loss : 0.5730 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.1106 train_acc : 0.4356 val_loss : 0.7639 val_acc : 0.9307\n",
      "Epoch: 0201 train_loss : 0.9248 train_acc : 0.5991 val_loss : 0.8759 val_acc : 0.7317\n",
      "Epoch: 0301 train_loss : 0.8458 train_acc : 0.6542 val_loss : 0.8495 val_acc : 0.7103\n",
      "Epoch: 0401 train_loss : 0.7672 train_acc : 0.6984 val_loss : 0.8216 val_acc : 0.7373\n",
      "Epoch: 0501 train_loss : 0.7160 train_acc : 0.7276 val_loss : 0.7590 val_acc : 0.7900\n",
      "Epoch: 0601 train_loss : 0.6847 train_acc : 0.7440 val_loss : 0.6935 val_acc : 0.8350\n",
      "Epoch: 0701 train_loss : 0.6532 train_acc : 0.7573 val_loss : 0.6413 val_acc : 0.8617\n",
      "Epoch: 0801 train_loss : 0.6351 train_acc : 0.7684 val_loss : 0.6019 val_acc : 0.8707\n",
      "Epoch: 0901 train_loss : 0.6171 train_acc : 0.7781 val_loss : 0.5629 val_acc : 0.8777\n",
      "Epoch: 1001 train_loss : 0.5972 train_acc : 0.7870 val_loss : 0.5466 val_acc : 0.8790\n",
      "Epoch: 1101 train_loss : 0.5791 train_acc : 0.7890 val_loss : 0.5515 val_acc : 0.8790\n",
      "Epoch: 1201 train_loss : 0.5647 train_acc : 0.7895 val_loss : 0.5317 val_acc : 0.8810\n",
      "Epoch: 1301 train_loss : 0.5533 train_acc : 0.7954 val_loss : 0.5121 val_acc : 0.8817\n",
      "Epoch: 1401 train_loss : 0.5425 train_acc : 0.7979 val_loss : 0.4909 val_acc : 0.8830\n",
      "Epoch: 1501 train_loss : 0.5306 train_acc : 0.8007 val_loss : 0.4683 val_acc : 0.8847\n",
      "Epoch: 1601 train_loss : 0.5178 train_acc : 0.8048 val_loss : 0.4505 val_acc : 0.8820\n",
      "Epoch: 1701 train_loss : 0.5098 train_acc : 0.8085 val_loss : 0.4349 val_acc : 0.8763\n",
      "Epoch: 1801 train_loss : 0.5025 train_acc : 0.8085 val_loss : 0.4110 val_acc : 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1901 train_loss : 0.4915 train_acc : 0.8126 val_loss : 0.3972 val_acc : 0.8757\n",
      "Epoch: 2001 train_loss : 0.4815 train_acc : 0.8185 val_loss : 0.3868 val_acc : 0.8687\n",
      "Epoch: 2101 train_loss : 0.4786 train_acc : 0.8204 val_loss : 0.3761 val_acc : 0.8683\n",
      "Epoch: 2201 train_loss : 0.4720 train_acc : 0.8251 val_loss : 0.3629 val_acc : 0.8683\n",
      "Epoch: 2301 train_loss : 0.4637 train_acc : 0.8279 val_loss : 0.3506 val_acc : 0.8697\n",
      "Epoch: 2401 train_loss : 0.4579 train_acc : 0.8282 val_loss : 0.3448 val_acc : 0.8700\n",
      "Epoch: 2501 train_loss : 0.4530 train_acc : 0.8304 val_loss : 0.3346 val_acc : 0.8720\n",
      "Epoch: 2601 train_loss : 0.4478 train_acc : 0.8293 val_loss : 0.3295 val_acc : 0.8717\n",
      "Epoch: 2701 train_loss : 0.4445 train_acc : 0.8324 val_loss : 0.3208 val_acc : 0.8727\n",
      "Epoch: 2801 train_loss : 0.4424 train_acc : 0.8326 val_loss : 0.3101 val_acc : 0.8753\n",
      "Epoch: 2901 train_loss : 0.4368 train_acc : 0.8340 val_loss : 0.3076 val_acc : 0.8750\n",
      "Epoch: 3001 train_loss : 0.4351 train_acc : 0.8332 val_loss : 0.3036 val_acc : 0.8747\n",
      "Epoch: 3101 train_loss : 0.4303 train_acc : 0.8354 val_loss : 0.2917 val_acc : 0.8773\n",
      "Epoch: 3201 train_loss : 0.4246 train_acc : 0.8363 val_loss : 0.2866 val_acc : 0.8777\n",
      "Epoch: 3301 train_loss : 0.4239 train_acc : 0.8374 val_loss : 0.2816 val_acc : 0.8787\n",
      "Epoch: 3401 train_loss : 0.4187 train_acc : 0.8382 val_loss : 0.2799 val_acc : 0.8783\n",
      "Epoch: 3501 train_loss : 0.4160 train_acc : 0.8401 val_loss : 0.2740 val_acc : 0.8803\n",
      "Epoch: 3601 train_loss : 0.4114 train_acc : 0.8396 val_loss : 0.2667 val_acc : 0.8820\n",
      "Epoch: 3701 train_loss : 0.4107 train_acc : 0.8429 val_loss : 0.2619 val_acc : 0.8847\n",
      "Epoch: 3801 train_loss : 0.4038 train_acc : 0.8435 val_loss : 0.2630 val_acc : 0.8820\n",
      "Epoch: 3901 train_loss : 0.4012 train_acc : 0.8438 val_loss : 0.2587 val_acc : 0.8823\n",
      "Epoch: 4001 train_loss : 0.4027 train_acc : 0.8457 val_loss : 0.2565 val_acc : 0.8827\n",
      "Epoch: 4101 train_loss : 0.3976 train_acc : 0.8465 val_loss : 0.2546 val_acc : 0.8823\n",
      "Epoch: 4201 train_loss : 0.3993 train_acc : 0.8477 val_loss : 0.2560 val_acc : 0.8817\n",
      "Epoch: 4301 train_loss : 0.3969 train_acc : 0.8474 val_loss : 0.2494 val_acc : 0.8837\n",
      "Epoch: 4401 train_loss : 0.3973 train_acc : 0.8488 val_loss : 0.2501 val_acc : 0.8833\n",
      "Epoch: 4501 train_loss : 0.3918 train_acc : 0.8493 val_loss : 0.2486 val_acc : 0.8840\n",
      "Epoch: 4601 train_loss : 0.3869 train_acc : 0.8502 val_loss : 0.2316 val_acc : 0.8847\n",
      "Epoch: 4701 train_loss : 0.3853 train_acc : 0.8513 val_loss : 0.2315 val_acc : 0.8840\n",
      "Epoch: 4801 train_loss : 0.3814 train_acc : 0.8521 val_loss : 0.2326 val_acc : 0.8843\n",
      "Epoch: 4901 train_loss : 0.3788 train_acc : 0.8513 val_loss : 0.2372 val_acc : 0.8830\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.84732854\n",
      "Execution time (seconds) was 124.515\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/15/\n",
      "[0.85121951 0.856371   0.85316355]\n",
      "[0.02694642 0.91737266 0.03650669]\n",
      "Using activation combination 16 : elu + elu\n",
      "Epoch: 0001 train_loss : 1.2753 train_acc : 0.3333 val_loss : 0.4580 val_acc : 0.9970\n",
      "Epoch: 0101 train_loss : 1.0547 train_acc : 0.4507 val_loss : 0.7653 val_acc : 0.9650\n",
      "Epoch: 0201 train_loss : 0.8620 train_acc : 0.6294 val_loss : 0.6070 val_acc : 0.8987\n",
      "Epoch: 0301 train_loss : 0.7229 train_acc : 0.7070 val_loss : 0.4605 val_acc : 0.8457\n",
      "Epoch: 0401 train_loss : 0.6333 train_acc : 0.7528 val_loss : 0.3827 val_acc : 0.8440\n",
      "Epoch: 0501 train_loss : 0.5814 train_acc : 0.7787 val_loss : 0.3512 val_acc : 0.8467\n",
      "Epoch: 0601 train_loss : 0.5476 train_acc : 0.7862 val_loss : 0.3270 val_acc : 0.8487\n",
      "Epoch: 0701 train_loss : 0.5235 train_acc : 0.7948 val_loss : 0.3106 val_acc : 0.8503\n",
      "Epoch: 0801 train_loss : 0.5091 train_acc : 0.7979 val_loss : 0.2939 val_acc : 0.8560\n",
      "Epoch: 0901 train_loss : 0.4957 train_acc : 0.8012 val_loss : 0.2721 val_acc : 0.8603\n",
      "Epoch: 1001 train_loss : 0.4875 train_acc : 0.8048 val_loss : 0.2656 val_acc : 0.8607\n",
      "Epoch: 1101 train_loss : 0.4777 train_acc : 0.8073 val_loss : 0.2595 val_acc : 0.8620\n",
      "Epoch: 1201 train_loss : 0.4696 train_acc : 0.8104 val_loss : 0.2543 val_acc : 0.8630\n",
      "Epoch: 1301 train_loss : 0.4665 train_acc : 0.8104 val_loss : 0.2483 val_acc : 0.8630\n",
      "Epoch: 1401 train_loss : 0.4612 train_acc : 0.8146 val_loss : 0.2518 val_acc : 0.8613\n",
      "Epoch: 1501 train_loss : 0.4611 train_acc : 0.8162 val_loss : 0.2516 val_acc : 0.8613\n",
      "Epoch: 1601 train_loss : 0.4545 train_acc : 0.8173 val_loss : 0.2462 val_acc : 0.8623\n",
      "Epoch: 1701 train_loss : 0.4470 train_acc : 0.8190 val_loss : 0.2468 val_acc : 0.8637\n",
      "Epoch: 1801 train_loss : 0.4466 train_acc : 0.8212 val_loss : 0.2458 val_acc : 0.8640\n",
      "Epoch: 1901 train_loss : 0.4405 train_acc : 0.8224 val_loss : 0.2390 val_acc : 0.8653\n",
      "Epoch: 2001 train_loss : 0.4368 train_acc : 0.8246 val_loss : 0.2440 val_acc : 0.8653\n",
      "Epoch: 2101 train_loss : 0.4352 train_acc : 0.8254 val_loss : 0.2328 val_acc : 0.8663\n",
      "Epoch: 2201 train_loss : 0.4286 train_acc : 0.8276 val_loss : 0.2356 val_acc : 0.8683\n",
      "Epoch: 2301 train_loss : 0.4268 train_acc : 0.8287 val_loss : 0.2335 val_acc : 0.8703\n",
      "Epoch: 2401 train_loss : 0.4259 train_acc : 0.8318 val_loss : 0.2270 val_acc : 0.8723\n",
      "Epoch: 2501 train_loss : 0.4268 train_acc : 0.8293 val_loss : 0.2251 val_acc : 0.8733\n",
      "Epoch: 2601 train_loss : 0.4179 train_acc : 0.8329 val_loss : 0.2176 val_acc : 0.8770\n",
      "Epoch: 2701 train_loss : 0.4160 train_acc : 0.8338 val_loss : 0.2182 val_acc : 0.8787\n",
      "Epoch: 2801 train_loss : 0.4123 train_acc : 0.8349 val_loss : 0.2177 val_acc : 0.8780\n",
      "Epoch: 2901 train_loss : 0.4087 train_acc : 0.8354 val_loss : 0.2187 val_acc : 0.8770\n",
      "Epoch: 3001 train_loss : 0.4060 train_acc : 0.8349 val_loss : 0.2196 val_acc : 0.8767\n",
      "Epoch: 3101 train_loss : 0.4037 train_acc : 0.8363 val_loss : 0.2220 val_acc : 0.8767\n",
      "Epoch: 3201 train_loss : 0.4007 train_acc : 0.8376 val_loss : 0.2231 val_acc : 0.8773\n",
      "Epoch: 3301 train_loss : 0.3975 train_acc : 0.8363 val_loss : 0.2220 val_acc : 0.8777\n",
      "Epoch: 3401 train_loss : 0.3953 train_acc : 0.8374 val_loss : 0.2264 val_acc : 0.8767\n",
      "Epoch: 3501 train_loss : 0.3902 train_acc : 0.8379 val_loss : 0.2246 val_acc : 0.8767\n",
      "Epoch: 3601 train_loss : 0.3928 train_acc : 0.8393 val_loss : 0.2253 val_acc : 0.8767\n",
      "Epoch: 3701 train_loss : 0.3894 train_acc : 0.8393 val_loss : 0.2236 val_acc : 0.8780\n",
      "Epoch: 3801 train_loss : 0.3862 train_acc : 0.8385 val_loss : 0.2343 val_acc : 0.8737\n",
      "Epoch: 3901 train_loss : 0.3834 train_acc : 0.8410 val_loss : 0.2244 val_acc : 0.8777\n",
      "Epoch: 4001 train_loss : 0.3830 train_acc : 0.8435 val_loss : 0.2188 val_acc : 0.8793\n",
      "Epoch: 4101 train_loss : 0.3736 train_acc : 0.8424 val_loss : 0.2258 val_acc : 0.8780\n",
      "Epoch: 4201 train_loss : 0.3752 train_acc : 0.8438 val_loss : 0.2237 val_acc : 0.8790\n",
      "Epoch: 4301 train_loss : 0.3729 train_acc : 0.8440 val_loss : 0.2252 val_acc : 0.8787\n",
      "Epoch: 4401 train_loss : 0.3730 train_acc : 0.8471 val_loss : 0.2219 val_acc : 0.8793\n",
      "Epoch: 4501 train_loss : 0.3671 train_acc : 0.8482 val_loss : 0.2185 val_acc : 0.8797\n",
      "Epoch: 4601 train_loss : 0.3676 train_acc : 0.8488 val_loss : 0.2224 val_acc : 0.8790\n",
      "Epoch: 4701 train_loss : 0.3629 train_acc : 0.8507 val_loss : 0.2187 val_acc : 0.8803\n",
      "Epoch: 4801 train_loss : 0.3645 train_acc : 0.8521 val_loss : 0.2198 val_acc : 0.8800\n",
      "Epoch: 4901 train_loss : 0.3579 train_acc : 0.8538 val_loss : 0.2125 val_acc : 0.8820\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.80951446\n",
      "Execution time (seconds) was 124.251\n",
      "INFO:tensorflow:Restoring parameters from /Users/meihuaren/personal/DL_logs/activation_try/16/\n",
      "[0.85186672 0.87274368 0.83956574]\n",
      "[0.0296371  0.89463357 0.0313981 ]\n"
     ]
    }
   ],
   "source": [
    "index_list = [str(activations[0]).split(' ')[1]+'_'+str(activations[1]).split(' ')[1] for activations in activation_combs]\n",
    "accuracies_train = pd.DataFrame(columns = [-1,0,1], index = index_list)\n",
    "AUCs_train = pd.DataFrame(columns = [-1,0,1], index = index_list)\n",
    "accuracies_test = pd.DataFrame(columns = [-1,0,1], index = index_list)\n",
    "AUCs_test = pd.DataFrame(columns = [-1,0,1], index = index_list)\n",
    "\n",
    "count = 0\n",
    "for activations in activation_combs:\n",
    "    #activations = activation_combs[0]\n",
    "    count += 1\n",
    "    print('Using activation combination',str(count),':',str(activations[0]).split(' ')[1],'+',str(activations[1]).split(' ')[1])\n",
    "\n",
    "    ### Define the loss and optimzation\n",
    "    logits = RNN(X, weights, biases, activations)\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    #define the loss \n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "    #tf.equal: Returns the truth value of (x == y) element-wise.\n",
    "    #tf.cast: Casts a tensor to a new type. --- here it casts from boolean to float\n",
    "    #tf.argmax:Returns the index with the largest value across axes of a tensor. --- here along the axis of the vector\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "    ### Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        #please, make sure you changed for your own path \n",
    "        #log_files_path = '/Users/macbook/Desktop/DLFall2018/codes/DL project/tensorflow-master/logs'\n",
    "        log_files_path = '/Users/meihuaren/personal/DL_logs/activation_try/' + str(count) + '/'\n",
    "\n",
    "        #save and restore variables to and from checkpoints.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        #will work with this later\n",
    "        #saver.restore(sess, log_files_path+'multi_layer/model-checkpoint-66000')\n",
    "\n",
    "        loss_trace = []\n",
    "\n",
    "        num_examples = x_train.shape[0]\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(n_epoch):\n",
    "\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(num_examples/n_batch)\n",
    "\n",
    "            # Shuffle the data\n",
    "            np.random.seed(4720)\n",
    "            perm = np.arange(num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            x_train = x_train[perm]\n",
    "            y_train = y_train[perm]\n",
    "\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "\n",
    "                minibatch_x, minibatch_y = x_train[i*n_batch:(i+1)*n_batch], y_train[i*n_batch:(i+1)*n_batch]\n",
    "\n",
    "                #minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                # Fit training using batch data\n",
    "                #the training is done using the training dataset\n",
    "                sess.run(train_op, feed_dict={X: minibatch_x, Y: minibatch_y})\n",
    "                # Compute average loss\n",
    "                avg_cost += sess.run(loss_op, feed_dict={X: minibatch_x, Y: minibatch_y})/total_batch\n",
    "\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "\n",
    "                #the accuracy is evaluated using the validation dataset\n",
    "                train_acc = sess.run(accuracy, feed_dict={X: x_train, Y: y_train})\n",
    "                val_cost = sess.run(loss_op, feed_dict={X: x_valid, Y: y_valid})\n",
    "                acc = sess.run(accuracy, feed_dict={X: x_valid, Y: y_valid})\n",
    "                loss_trace.append(1-acc)    \n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \"train_loss :\", \"{:0.4f}\".format(avg_cost), \"train_acc :\", \"{:0.4f}\".format(train_acc), \\\n",
    "                      \"val_loss :\", \"{:0.4f}\".format(val_cost), \"val_acc :\", \"{:0.4f}\".format(acc))    \n",
    "\n",
    "        #save to use later\n",
    "        saver.save(sess, log_files_path)\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        #accuracy evaluated with the whole test dataset\n",
    "        acc = sess.run(accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "        print(\"Test Accuracy:\", acc)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Execution time (seconds) was %0.3f' % elapsed_time)\n",
    "\n",
    "\n",
    "    ### Evaluate the model\n",
    "    # returns a compiled model\n",
    "    # identical to the previous one\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, log_files_path)\n",
    "\n",
    "        pred = sess.run(prediction, feed_dict={X: x_train, Y: y_train})    \n",
    "        pred_df_train = pd.DataFrame(pred, columns=['-1', '0', '1'])\n",
    "        pred_df_train['predict'] = pred_df_train.idxmax(axis=1)\n",
    "        pred_df_train['true'] = pd.DataFrame(y_train, columns=['-1', '0', '1']).idxmax(axis=1)\n",
    "\n",
    "        pred = sess.run(prediction, feed_dict={X: x_test, Y: y_test})    \n",
    "        pred_df_test = pd.DataFrame(pred, columns=['-1', '0', '1'])\n",
    "        pred_df_test['predict'] = pred_df_test.idxmax(axis=1)\n",
    "        pred_df_test['true'] = pd.DataFrame(y_test, columns=['-1', '0', '1']).idxmax(axis=1)  \n",
    "\n",
    "    train_f1 = f1_score(pred_df_train.true, pred_df_train.predict, average=None)\n",
    "    test_f1 = f1_score(pred_df_test.true, pred_df_test.predict, average=None)\n",
    "    print (train_f1)\n",
    "    print (test_f1)\n",
    "\n",
    "\n",
    "    ### Results on training data\n",
    "    evaluator = MLEvaluator()\n",
    "    evaluator.set_pred_df(pred_df_train)\n",
    "\n",
    "    # compute & store accuracy\n",
    "    cf_mx_train = evaluator.generate_confusion_matrix()\n",
    "    cf_mx_train_normalized = cf_mx_train.values.astype('float') / cf_mx_train.values.sum(axis=1)[:, np.newaxis]\n",
    "    row_idx = str(activations[0]).split(' ')[1]+'_'+str(activations[1]).split(' ')[1]\n",
    "    accuracies_train.loc[row_idx, -1] = cf_mx_train_normalized[0][0]\n",
    "    accuracies_train.loc[row_idx, 0] = cf_mx_train_normalized[1][1]\n",
    "    accuracies_train.loc[row_idx, 1] = cf_mx_train_normalized[2][2]\n",
    "    #print(accuracies)\n",
    "\n",
    "    # compute & store AUC\n",
    "    for lab in evaluator.pred_df.true.unique():\n",
    "        fpr, tpr, thresholds = roc_curve(evaluator.pred_df.true, evaluator.pred_df[str(lab)], pos_label=lab)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        AUCs_train.loc[row_idx,int(lab)] = roc_auc\n",
    "        #print(lab,roc_auc)\n",
    "    #print(AUCs)\n",
    "\n",
    "    ### Results on testing data\n",
    "    evaluator = MLEvaluator()\n",
    "    evaluator.set_pred_df(pred_df_test)\n",
    "\n",
    "    # compute & store accuracy\n",
    "    cf_mx_train = evaluator.generate_confusion_matrix()\n",
    "    cf_mx_train_normalized = cf_mx_train.values.astype('float') / cf_mx_train.values.sum(axis=1)[:, np.newaxis]\n",
    "    row_idx = str(activations[0]).split(' ')[1]+'_'+str(activations[1]).split(' ')[1]\n",
    "    accuracies_test.loc[row_idx, -1] = cf_mx_train_normalized[0][0]\n",
    "    accuracies_test.loc[row_idx, 0] = cf_mx_train_normalized[1][1]\n",
    "    accuracies_test.loc[row_idx, 1] = cf_mx_train_normalized[2][2]\n",
    "    #print(accuracies)\n",
    "\n",
    "    # compute & store AUC\n",
    "    for lab in evaluator.pred_df.true.unique():\n",
    "        fpr, tpr, thresholds = roc_curve(evaluator.pred_df.true, evaluator.pred_df[str(lab)], pos_label=lab)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        AUCs_test.loc[row_idx,int(lab)] = roc_auc\n",
    "        #print(lab,roc_auc)\n",
    "    #print(AUCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output accuracy & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouput\n",
    "accuracies_train.to_csv('accuracies_train.csv')\n",
    "AUCs_train.to_csv('AUCs_train.csv')\n",
    "accuracies_test.to_csv('accuracies_test.csv')\n",
    "AUCs_test.to_csv('AUCs_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
